<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>pytorch lightning | lei’s blog’</title> <meta name="generator" content="Jekyll v3.9.3" /> <meta property="og:title" content="pytorch lightning" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="This is lei’s knowledge collection website, not for public use." /> <meta property="og:description" content="This is lei’s knowledge collection website, not for public use." /> <link rel="canonical" href="https://lei0lei.github.io/python/pytorch-lightning" /> <meta property="og:url" content="https://lei0lei.github.io/python/pytorch-lightning" /> <meta property="og:site_name" content="lei’s blog’" /> <meta property="og:type" content="website" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="pytorch lightning" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","description":"This is lei’s knowledge collection website, not for public use.","headline":"pytorch lightning","url":"https://lei0lei.github.io/python/pytorch-lightning"}</script> <!-- End Jekyll SEO tag --> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header"> <a href="/" class="site-title lh-tight"> lei's blog' </a> <a href="#" id="menu-button" class="site-button"> <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg> </a> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="/" class="nav-list-link">Home</a></li><li class="nav-list-item"><a href="#" class="nav-list-expander" aria-label="toggle links in DevOps category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/DevOps/" class="nav-list-link">DevOps</a><ul class="nav-list"><li class="nav-list-item "><a href="#" class="nav-list-expander" aria-label="toggle links in Git category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/DevOps/Git/" class="nav-list-link">Git</a><ul class="nav-list"></ul></li><li class="nav-list-item "><a href="#" class="nav-list-expander" aria-label="toggle links in Github category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/DevOps/Github/" class="nav-list-link">Github</a><ul class="nav-list"></ul></li><li class="nav-list-item "><a href="#" class="nav-list-expander" aria-label="toggle links in Gitlab category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/DevOps/Gitlab/" class="nav-list-link">Gitlab</a><ul class="nav-list"></ul></li><li class="nav-list-item "><a href="#" class="nav-list-expander" aria-label="toggle links in MLOps category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/DevOps/MLOps/" class="nav-list-link">MLOps</a><ul class="nav-list"></ul></li></ul></li><li class="nav-list-item active"><a href="#" class="nav-list-expander" aria-label="toggle links in MachineLearning category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/MachineLearning/" class="nav-list-link">MachineLearning</a><ul class="nav-list"><li class="nav-list-item "><a href="#" class="nav-list-expander" aria-label="toggle links in jax category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/MachineLearning/jax/" class="nav-list-link">jax</a><ul class="nav-list"></ul></li><li class="nav-list-item "><a href="#" class="nav-list-expander" aria-label="toggle links in model category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/MachineLearning/model/" class="nav-list-link">model</a><ul class="nav-list"><li class="nav-list-item "> <a href="/MachineLearning/model/CNN" class="nav-list-link">CNN</a> </li><li class="nav-list-item "> <a href="/MachineLearning/model/GNN" class="nav-list-link">GNN</a> </li><li class="nav-list-item "> <a href="/MachineLearning/model/RNN" class="nav-list-link">RNN</a> </li><li class="nav-list-item "> <a href="/MachineLearning/model/SVM" class="nav-list-link">SVM</a> </li><li class="nav-list-item "> <a href="/MachineLearning/model/Transformer" class="nav-list-link">Transformer</a> </li><li class="nav-list-item "> <a href="/MachineLearning/model/yolo" class="nav-list-link">yolo</a> </li></ul></li><li class="nav-list-item active"><a href="#" class="nav-list-expander" aria-label="toggle links in pytorch category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/MachineLearning/pytorch/" class="nav-list-link">pytorch</a><ul class="nav-list"><li class="nav-list-item "> <a href="/MachineLearning/pytorch/DP" class="nav-list-link">DP</a> </li><li class="nav-list-item "> <a href="/python/DVC" class="nav-list-link">DVC</a> </li><li class="nav-list-item "> <a href="/MachineLearning/pytorch/NN" class="nav-list-link">NN</a> </li><li class="nav-list-item "> <a href="/MachineLearning/pytorch/autograd" class="nav-list-link">autograd</a> </li><li class="nav-list-item "> <a href="/MachineLearning/pytorch/basis" class="nav-list-link">basis</a> </li><li class="nav-list-item "> <a href="/MachineLearning/pytorch/cuda" class="nav-list-link">cuda</a> </li><li class="nav-list-item "> <a href="/MachineLearning/pytorch/frontend" class="nav-list-link">frontend</a> </li><li class="nav-list-item "> <a href="/MachineLearning/pytorch/internal" class="nav-list-link">internal</a> </li><li class="nav-list-item "> <a href="/python/mlflow" class="nav-list-link">mlflow</a> </li><li class="nav-list-item "> <a href="/MachineLearning/pytorch/optimize" class="nav-list-link">optimize</a> </li><li class="nav-list-item active"> <a href="/python/pytorch-lightning" class="nav-list-link active">pytorch lightning</a> </li><li class="nav-list-item "> <a href="/python/steps2model" class="nav-list-link">steps2model</a> </li></ul></li></ul></li><li class="nav-list-item"><a href="#" class="nav-list-expander" aria-label="toggle links in cpp category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/cpp/" class="nav-list-link">cpp</a><ul class="nav-list"><li class="nav-list-item "><a href="#" class="nav-list-expander" aria-label="toggle links in GSL category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/cpp/GSL/" class="nav-list-link">GSL</a><ul class="nav-list"></ul></li><li class="nav-list-item "><a href="#" class="nav-list-expander" aria-label="toggle links in STL category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/cpp/STL/" class="nav-list-link">STL</a><ul class="nav-list"></ul></li><li class="nav-list-item "><a href="#" class="nav-list-expander" aria-label="toggle links in StandardLibrary category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/cpp/StandardLibrary/" class="nav-list-link">StandardLibrary</a><ul class="nav-list"></ul></li></ul></li><li class="nav-list-item"><a href="#" class="nav-list-expander" aria-label="toggle links in designpattern category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/designpattern/" class="nav-list-link">designpattern</a><ul class="nav-list"><li class="nav-list-item "><a href="#" class="nav-list-expander" aria-label="toggle links in EventDriven category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/designpattern/EventDriven" class="nav-list-link">EventDriven</a><ul class="nav-list"></ul></li><li class="nav-list-item "><a href="#" class="nav-list-expander" aria-label="toggle links in ServiceOriented category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/designpattern/ServiceOriented" class="nav-list-link">ServiceOriented</a><ul class="nav-list"></ul></li></ul></li><li class="nav-list-item"><a href="#" class="nav-list-expander" aria-label="toggle links in go category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/go/" class="nav-list-link">go</a><ul class="nav-list"></ul></li><li class="nav-list-item"><a href="#" class="nav-list-expander" aria-label="toggle links in howtos category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/how-tos/" class="nav-list-link">howtos</a><ul class="nav-list"><li class="nav-list-item "><a href="/how-tos/github-pages/" class="nav-list-link">howtos-ghpages</a></li></ul></li><li class="nav-list-item"><a href="/micellaneous/" class="nav-list-link">micellaneous</a></li><li class="nav-list-item"><a href="#" class="nav-list-expander" aria-label="toggle links in python category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/python/" class="nav-list-link">python</a><ul class="nav-list"><li class="nav-list-item "><a href="/python/101" class="nav-list-link">101</a></li><li class="nav-list-item "><a href="/python/DependencyInjector" class="nav-list-link">DependencyInjector</a></li><li class="nav-list-item "><a href="#" class="nav-list-expander" aria-label="toggle links in DesignPattern category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/python/DesignPattern/" class="nav-list-link">DesignPattern</a><ul class="nav-list"><li class="nav-list-item "> <a href="/MachineLearning/designpattern/functionmethod" class="nav-list-link">Factory Method Pattern</a> </li></ul></li><li class="nav-list-item "><a href="/python/OOP" class="nav-list-link">OOP</a></li><li class="nav-list-item "><a href="/python/asyncio" class="nav-list-link">asyncio</a></li><li class="nav-list-item "><a href="/python/dataclass" class="nav-list-link">dataclass</a></li><li class="nav-list-item "><a href="/python/decorator" class="nav-list-link">decorator</a></li><li class="nav-list-item "><a href="/python/import" class="nav-list-link">import</a></li><li class="nav-list-item "><a href="/python/interface" class="nav-list-link">interface</a></li><li class="nav-list-item "><a href="/python/iterator" class="nav-list-link">iterator</a></li><li class="nav-list-item "><a href="#" class="nav-list-expander" aria-label="toggle links in packages category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/python/packages" class="nav-list-link">packages</a><ul class="nav-list"><li class="nav-list-item "> <a href="/MachineLearning/packages/attrs" class="nav-list-link">attrs</a> </li><li class="nav-list-item "> <a href="/MachineLearning/packages/click" class="nav-list-link">click</a> </li><li class="nav-list-item "> <a href="/MachineLearning/packages/cookiecutter" class="nav-list-link">cookiecutter</a> </li><li class="nav-list-item "> <a href="/MachineLearning/packages/functools" class="nav-list-link">functools</a> </li><li class="nav-list-item "> <a href="/MachineLearning/packages/manim" class="nav-list-link">manim</a> </li><li class="nav-list-item "> <a href="/MachineLearning/packages/numpy" class="nav-list-link">numpy</a> </li><li class="nav-list-item "> <a href="/MachineLearning/packages/pandas" class="nav-list-link">pandas</a> </li><li class="nav-list-item "> <a href="/MachineLearning/packages/pants" class="nav-list-link">pants</a> </li><li class="nav-list-item "> <a href="/MachineLearning/packages/pytest" class="nav-list-link">pytest</a> </li><li class="nav-list-item "> <a href="/MachineLearning/packages/rich" class="nav-list-link">rich</a> </li><li class="nav-list-item "> <a href="/MachineLearning/packages/scipy" class="nav-list-link">scipy</a> </li><li class="nav-list-item "> <a href="/MachineLearning/packages/sqlAlchemy" class="nav-list-link">sqlAlchemy</a> </li><li class="nav-list-item "> <a href="/MachineLearning/packages/tqdm" class="nav-list-link">tqdm</a> </li></ul></li><li class="nav-list-item "><a href="/python/style" class="nav-list-link">python style</a></li></ul></li><li class="nav-list-item"><a href="#" class="nav-list-expander" aria-label="toggle links in web category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/web/" class="nav-list-link">web</a><ul class="nav-list"><li class="nav-list-item "><a href="#" class="nav-list-expander" aria-label="toggle links in js category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/web/js" class="nav-list-link">js</a><ul class="nav-list"><li class="nav-list-item "> <a href="/web/js/basics" class="nav-list-link">basics</a> </li><li class="nav-list-item "> <a href="/web/js/objects" class="nav-list-link">objects</a> </li><li class="nav-list-item "> <a href="/web/js/styles" class="nav-list-link">styles</a> </li></ul></li><li class="nav-list-item "><a href="#" class="nav-list-expander" aria-label="toggle links in nodejs category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/web/nodejs" class="nav-list-link">nodejs</a><ul class="nav-list"></ul></li><li class="nav-list-item "><a href="#" class="nav-list-expander" aria-label="toggle links in wasm category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/web/wasm" class="nav-list-link">wasm</a><ul class="nav-list"></ul></li></ul></li></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search lei's blog'" aria-label="Search lei's blog'" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> </div> <div id="main-content-wrap" class="main-content-wrap"> <nav aria-label="Breadcrumb" class="breadcrumb-nav"> <ol class="breadcrumb-nav-list"> <li class="breadcrumb-nav-list-item"><a href="/MachineLearning/">MachineLearning</a></li> <li class="breadcrumb-nav-list-item"><a href="/MachineLearning/pytorch/">pytorch</a></li> <li class="breadcrumb-nav-list-item"><span>pytorch lightning</span></li> </ol> </nav> <div id="main-content" class="main-content" role="main"> <details open=""> <summary class="text-delta"> Table of contents </summary> <ol id="markdown-toc"> <li><a href="#7个关键步骤" id="markdown-toc-7个关键步骤">7个关键步骤</a> <ol> <li><a href="#定义lightningmodule" id="markdown-toc-定义lightningmodule">定义LightningModule</a></li> <li><a href="#定义数据集" id="markdown-toc-定义数据集">定义数据集</a></li> <li><a href="#模型训练" id="markdown-toc-模型训练">模型训练</a></li> <li><a href="#模型的使用" id="markdown-toc-模型的使用">模型的使用</a></li> <li><a href="#训练可视化" id="markdown-toc-训练可视化">训练可视化</a></li> <li><a href="#supercharge-training" id="markdown-toc-supercharge-training">Supercharge training</a></li> </ol> </li> <li><a href="#模型训练-1" id="markdown-toc-模型训练-1">模型训练</a> <ol> <li><a href="#import" id="markdown-toc-import">import</a></li> <li><a href="#定义nnmodules" id="markdown-toc-定义nnmodules">定义nn.Modules</a></li> <li><a href="#定义lightningmodule-1" id="markdown-toc-定义lightningmodule-1">定义LightningModule</a></li> <li><a href="#定义训练集" id="markdown-toc-定义训练集">定义训练集</a></li> <li><a href="#模型训练-2" id="markdown-toc-模型训练-2">模型训练</a></li> <li><a href="#干掉训练循环" id="markdown-toc-干掉训练循环">干掉训练循环</a></li> </ol> </li> <li><a href="#添加验证集和测试集" id="markdown-toc-添加验证集和测试集">添加验证集和测试集</a> <ol> <li><a href="#分割数据集" id="markdown-toc-分割数据集">分割数据集</a></li> <li><a href="#定义测试循环" id="markdown-toc-定义测试循环">定义测试循环</a></li> <li><a href="#训练之后加入测试步骤" id="markdown-toc-训练之后加入测试步骤">训练之后加入测试步骤</a></li> <li><a href="#添加验证循环" id="markdown-toc-添加验证循环">添加验证循环</a></li> </ol> </li> <li><a href="#保存模型过程" id="markdown-toc-保存模型过程">保存模型过程</a> <ol> <li><a href="#保存ckpt" id="markdown-toc-保存ckpt">保存ckpt</a></li> <li><a href="#加载" id="markdown-toc-加载">加载</a></li> <li><a href="#nnmodule-from-checkpoint" id="markdown-toc-nnmodule-from-checkpoint">nn.Module from checkpoint</a></li> <li><a href="#禁用ckpt" id="markdown-toc-禁用ckpt">禁用ckpt</a></li> <li><a href="#恢复训练" id="markdown-toc-恢复训练">恢复训练</a></li> </ol> </li> <li><a href="#提前终止训练" id="markdown-toc-提前终止训练">提前终止训练</a></li> <li><a href="#迁移学习" id="markdown-toc-迁移学习">迁移学习</a> <ol> <li><a href="#使用预训练的lightningmodule" id="markdown-toc-使用预训练的lightningmodule">使用预训练的<code class="language-plaintext highlighter-rouge">LightningModule</code></a></li> <li><a href="#bert" id="markdown-toc-bert">Bert</a></li> </ol> </li> <li><a href="#命令行中配置超参数" id="markdown-toc-命令行中配置超参数">命令行中配置超参数</a> <ol> <li><a href="#argumentparser" id="markdown-toc-argumentparser">ArgumentParser</a></li> <li><a href="#lightning-cli" id="markdown-toc-lightning-cli">lightning cli</a></li> </ol> </li> <li><a href="#debug可视化以及寻找瓶颈" id="markdown-toc-debug可视化以及寻找瓶颈">debug,可视化以及寻找瓶颈</a> <ol> <li><a href="#debug" id="markdown-toc-debug">debug</a> <ol> <li><a href="#设置断点" id="markdown-toc-设置断点">设置断点</a></li> <li><a href="#跑一遍代码" id="markdown-toc-跑一遍代码">跑一遍代码</a></li> <li><a href="#缩短epoch长度" id="markdown-toc-缩短epoch长度">缩短epoch长度</a></li> <li><a href="#简单检查" id="markdown-toc-简单检查">简单检查</a></li> <li><a href="#显示lightningmodule权重summary" id="markdown-toc-显示lightningmodule权重summary">显示<code class="language-plaintext highlighter-rouge">LightningModule</code>权重summary</a></li> <li><a href="#查找代码瓶颈" id="markdown-toc-查找代码瓶颈">查找代码瓶颈</a></li> <li><a href="#实验跟踪和可视化" id="markdown-toc-实验跟踪和可视化">实验跟踪和可视化</a> <ol> <li><a href="#metrics跟踪" id="markdown-toc-metrics跟踪">metrics跟踪</a></li> </ol> </li> </ol> </li> </ol> </li> <li><a href="#模型推理" id="markdown-toc-模型推理">模型推理</a> <ol> <li><a href="#产品级部署-1" id="markdown-toc-产品级部署-1">产品级部署-1</a> <ol> <li><a href="#加载ckpt并预测" id="markdown-toc-加载ckpt并预测">加载ckpt并预测</a></li> <li><a href="#lightningmodule添加预测过程" id="markdown-toc-lightningmodule添加预测过程"><code class="language-plaintext highlighter-rouge">LightningModule</code>添加预测过程</a></li> <li><a href="#添加复杂的推理逻辑" id="markdown-toc-添加复杂的推理逻辑">添加复杂的推理逻辑</a></li> <li><a href="#使用分布式推理" id="markdown-toc-使用分布式推理">使用分布式推理</a></li> </ol> </li> <li><a href="#产品级部署-2" id="markdown-toc-产品级部署-2">产品级部署-2</a> <ol> <li><a href="#使用pytorch" id="markdown-toc-使用pytorch">使用pytorch</a></li> <li><a href="#从lightning中提取nnmodules" id="markdown-toc-从lightning中提取nnmodules">从lightning中提取<code class="language-plaintext highlighter-rouge">nn.Modules</code></a></li> </ol> </li> </ol> </li> <li><a href="#gpu训练" id="markdown-toc-gpu训练">GPU训练</a> <ol> <li><a href="#代码修改" id="markdown-toc-代码修改">代码修改</a> <ol> <li><a href="#remove-samplers" id="markdown-toc-remove-samplers">Remove samplers</a></li> <li><a href="#同步" id="markdown-toc-同步">同步</a></li> <li><a href="#pickleable-model" id="markdown-toc-pickleable-model">pickleable model</a></li> </ol> </li> <li><a href="#gpu训练-1" id="markdown-toc-gpu训练-1">gpu训练</a></li> </ol> </li> <li><a href="#项目模块化" id="markdown-toc-项目模块化">项目模块化</a> <ol> <li><a href="#datamodule" id="markdown-toc-datamodule">datamodule</a> <ol> <li><a href="#prepare_data" id="markdown-toc-prepare_data">prepare_data</a></li> <li><a href="#setup" id="markdown-toc-setup">setup</a></li> <li><a href="#train_dataloader" id="markdown-toc-train_dataloader">train_dataloader</a></li> <li><a href="#val_dataloader" id="markdown-toc-val_dataloader">val_dataloader</a></li> <li><a href="#test_dataloader" id="markdown-toc-test_dataloader">test_dataloader</a></li> <li><a href="#predict_dataloader" id="markdown-toc-predict_dataloader">predict_dataloader</a></li> <li><a href="#transfer_batch_to_device" id="markdown-toc-transfer_batch_to_device">transfer_batch_to_device</a></li> <li><a href="#on_before_batch_transfer" id="markdown-toc-on_before_batch_transfer">on_before_batch_transfer</a></li> <li><a href="#on_after_batch_transfer" id="markdown-toc-on_after_batch_transfer">on_after_batch_transfer</a></li> <li><a href="#load_state_dict" id="markdown-toc-load_state_dict">load_state_dict</a></li> <li><a href="#state_dict" id="markdown-toc-state_dict">state_dict</a></li> <li><a href="#teardown" id="markdown-toc-teardown">teardown</a></li> <li><a href="#prepare_data_per_node" id="markdown-toc-prepare_data_per_node">prepare_data_per_node</a></li> <li><a href="#使用datamodule" id="markdown-toc-使用datamodule">使用datamodule</a></li> <li><a href="#在pytorch中使用datamodules" id="markdown-toc-在pytorch中使用datamodules">在pytorch中使用DataModules</a></li> <li><a href="#datamodule中的超参数" id="markdown-toc-datamodule中的超参数">datamodule中的超参数</a></li> <li><a href="#保存datamodule-state" id="markdown-toc-保存datamodule-state">保存datamodule state</a></li> </ol> </li> <li><a href="#cli中配置超参数-1" id="markdown-toc-cli中配置超参数-1">CLI中配置超参数-1</a> <ol> <li><a href="#实现cli" id="markdown-toc-实现cli">实现CLI</a></li> <li><a href="#使用cli训练模型" id="markdown-toc-使用cli训练模型">使用CLI训练模型</a></li> </ol> </li> <li><a href="#cli中配置超参数-2" id="markdown-toc-cli中配置超参数-2">CLI中配置超参数-2</a> <ol> <li><a href="#多个lightningmodules" id="markdown-toc-多个lightningmodules">多个LightningModules</a></li> <li><a href="#多个-lightningdatamodules" id="markdown-toc-多个-lightningdatamodules">多个 LightningDataModules</a></li> <li><a href="#多个优化器" id="markdown-toc-多个优化器">多个优化器</a></li> <li><a href="#多个scheduler" id="markdown-toc-多个scheduler">多个scheduler</a></li> <li><a href="#其他包中的类" id="markdown-toc-其他包中的类">其他包中的类</a></li> <li><a href="#模型help" id="markdown-toc-模型help">模型help</a></li> </ol> </li> <li><a href="#cli中配置超参数-3" id="markdown-toc-cli中配置超参数-3">CLI中配置超参数-3</a> <ol> <li><a href="#为cli准备config文件" id="markdown-toc-为cli准备config文件">为CLI准备config文件</a></li> <li><a href="#组合配置文件" id="markdown-toc-组合配置文件">组合配置文件</a></li> </ol> </li> <li><a href="#cli中配置超参数-4" id="markdown-toc-cli中配置超参数-4">CLI中配置超参数-4</a> <ol> <li><a href="#变量插入" id="markdown-toc-变量插入">变量插入</a></li> </ol> </li> <li><a href="#cli中配置超参数-5" id="markdown-toc-cli中配置超参数-5">CLI中配置超参数-5</a> <ol> <li><a href="#trainer回调和class-type参数" id="markdown-toc-trainer回调和class-type参数">Trainer回调和class type参数</a></li> <li><a href="#多个模型和数据集" id="markdown-toc-多个模型和数据集">多个模型和数据集</a></li> <li><a href="#有多个子模块的模型" id="markdown-toc-有多个子模块的模型">有多个子模块的模型</a></li> <li><a href="#固定optimizer和scheduler" id="markdown-toc-固定optimizer和scheduler">固定optimizer和scheduler</a></li> <li><a href="#多个optimizer和scheduler" id="markdown-toc-多个optimizer和scheduler">多个optimizer和scheduler</a></li> <li><a href="#从python运行" id="markdown-toc-从python运行">从python运行</a></li> </ol> </li> <li><a href="#cli中配置超参数-6" id="markdown-toc-cli中配置超参数-6">CLI中配置超参数-6</a> <ol> <li><a href="#强制callback" id="markdown-toc-强制callback">强制callback</a></li> <li><a href="#class-type-defaults" id="markdown-toc-class-type-defaults">Class type defaults</a></li> <li><a href="#参数链接" id="markdown-toc-参数链接">参数链接</a></li> </ol> </li> </ol> </li> <li><a href="#checkpoint" id="markdown-toc-checkpoint">checkpoint</a></li> <li><a href="#实验管理" id="markdown-toc-实验管理">实验管理</a></li> <li><a href="#progress-bar" id="markdown-toc-progress-bar">PROGRESS BAR</a> <ol> <li><a href="#richprogressbar" id="markdown-toc-richprogressbar">RichProgressBar</a></li> </ol> </li> <li><a href="#gpu" id="markdown-toc-gpu">GPU</a></li> <li><a href="#并行" id="markdown-toc-并行">并行</a></li> </ol> </details> <h1 id="7个关键步骤"> <a href="#7个关键步骤" class="anchor-heading" aria-labelledby="7个关键步骤"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 7个关键步骤 </h1> <h2 id="定义lightningmodule"> <a href="#定义lightningmodule" class="anchor-heading" aria-labelledby="定义lightningmodule"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 定义LightningModule </h2> <p>LightningModule把pytorch的nn.module放到了一起，数据处理，训练等步骤都包在一个类中。</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">utils</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">torchvision.datasets</span> <span class="kn">import</span> <span class="n">MNIST</span>
<span class="kn">from</span> <span class="nn">torchvision.transforms</span> <span class="kn">import</span> <span class="n">ToTensor</span>
<span class="kn">import</span> <span class="nn">lightning.pytorch</span> <span class="k">as</span> <span class="n">pl</span>

<span class="c1"># define any number of nn.Modules (or use your current ones)
</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">))</span>


<span class="c1"># define the LightningModule
</span><span class="k">class</span> <span class="nc">LitAutoEncoder</span><span class="p">(</span><span class="n">pl</span><span class="p">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="c1"># training_step defines the train loop.
</span>        <span class="c1"># it is independent of forward
</span>        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">x_hat</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="c1"># Logging to TensorBoard (if installed) by default
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="s">"train_loss"</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">optimizer</span>


<span class="c1"># init the autoencoder
</span><span class="n">autoencoder</span> <span class="o">=</span> <span class="n">LitAutoEncoder</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">)</span>
</code></pre></div></div> <h2 id="定义数据集"> <a href="#定义数据集" class="anchor-heading" aria-labelledby="定义数据集"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 定义数据集 </h2> <p>lightning支持任何iterable类型。</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dataset</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">ToTensor</span><span class="p">())</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</code></pre></div></div> <h2 id="模型训练"> <a href="#模型训练" class="anchor-heading" aria-labelledby="模型训练"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 模型训练 </h2> <p>Lightning 的Trainer 可以混合使用任意的 LightningModule 和任意的数据集。</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># train the model (hint: here are some helpful Trainer arguments for rapid idea iteration)
</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="p">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">limit_train_batches</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">trainer</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">autoencoder</span><span class="p">,</span> <span class="n">train_dataloaders</span><span class="o">=</span><span class="n">train_loader</span><span class="p">)</span>
</code></pre></div></div> <p>Trainer支持40多种tricks.</p> <ul> <li>Epoch and batch iteration</li> <li>optimizer.step(), loss.backward(), optimizer.zero_grad() 调用</li> <li>调用model.eval(), 阶段禁用或者启用grads.</li> <li>Checkpoint 保存和加载</li> <li>Tensorboard (see loggers options)</li> <li>Multi-GPU</li> <li>TPU</li> <li>16-bit precision AMP</li> </ul> <h2 id="模型的使用"> <a href="#模型的使用" class="anchor-heading" aria-labelledby="模型的使用"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 模型的使用 </h2> <p>支持产品级部署</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># load checkpoint
</span><span class="n">checkpoint</span> <span class="o">=</span> <span class="s">"./lightning_logs/version_0/checkpoints/epoch=0-step=100.ckpt"</span>
<span class="n">autoencoder</span> <span class="o">=</span> <span class="n">LitAutoEncoder</span><span class="p">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="o">=</span><span class="n">decoder</span><span class="p">)</span>

<span class="c1"># choose your trained nn.Module
</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="p">.</span><span class="n">encoder</span>
<span class="n">encoder</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>

<span class="c1"># embed 4 fake images!
</span><span class="n">fake_image_batch</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">fake_image_batch</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"⚡"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">,</span> <span class="s">"</span><span class="se">\n</span><span class="s">Predictions (4 image embeddings):</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="s">"⚡"</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>
</code></pre></div></div> <h2 id="训练可视化"> <a href="#训练可视化" class="anchor-heading" aria-labelledby="训练可视化"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 训练可视化 </h2> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tensorboard</span> <span class="o">--</span><span class="n">logdir</span> <span class="p">.</span>
</code></pre></div></div> <h2 id="supercharge-training"> <a href="#supercharge-training" class="anchor-heading" aria-labelledby="supercharge-training"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Supercharge training </h2> <p>在trainer中传入参数支持高级的训练特征。</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># train on 4 GPUs
</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">devices</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">accelerator</span><span class="o">=</span><span class="s">"gpu"</span><span class="p">,</span>
 <span class="p">)</span>

<span class="c1"># train 1TB+ parameter models with Deepspeed/fsdp
</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">devices</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">accelerator</span><span class="o">=</span><span class="s">"gpu"</span><span class="p">,</span>
    <span class="n">strategy</span><span class="o">=</span><span class="s">"deepspeed_stage_2"</span><span class="p">,</span>
    <span class="n">precision</span><span class="o">=</span><span class="mi">16</span>
 <span class="p">)</span>

<span class="c1"># 20+ helpful flags for rapid idea iteration
</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">min_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">overfit_batches</span><span class="o">=</span><span class="mi">1</span>
 <span class="p">)</span>

<span class="c1"># access the latest state of the art techniques
</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">StochasticWeightAveraging</span><span class="p">(...)])</span>
</code></pre></div></div> <p>lightning提供了额外的灵活度，可以自定义训练循环，</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LitAutoEncoder</span><span class="p">(</span><span class="n">pl</span><span class="p">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
</code></pre></div></div> <p>扩展trainer：</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">AWSCheckpoints</span><span class="p">()])</span>
</code></pre></div></div> <h1 id="模型训练-1"> <a href="#模型训练-1" class="anchor-heading" aria-labelledby="模型训练-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 模型训练 </h1> <h2 id="import"> <a href="#import" class="anchor-heading" aria-labelledby="import"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> import </h2> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">torchvision.datasets</span> <span class="kn">import</span> <span class="n">MNIST</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="nn">lightning.pytorch</span> <span class="k">as</span> <span class="n">pl</span>
</code></pre></div></div> <h2 id="定义nnmodules"> <a href="#定义nnmodules" class="anchor-heading" aria-labelledby="定义nnmodules"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 定义nn.Modules </h2> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div> <h2 id="定义lightningmodule-1"> <a href="#定义lightningmodule-1" class="anchor-heading" aria-labelledby="定义lightningmodule-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 定义LightningModule </h2> <ul> <li><code class="language-plaintext highlighter-rouge">training_step</code>定义<code class="language-plaintext highlighter-rouge">nn.Modules</code>的交互</li> <li><code class="language-plaintext highlighter-rouge">configure_optimizers</code>定义模型的优化器 <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LitAutoEncoder</span><span class="p">(</span><span class="n">pl</span><span class="p">.</span><span class="n">LightningModule</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">):</span>
      <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
      <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>

  <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
      <span class="c1"># training_step defines the train loop.
</span>      <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
      <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
      <span class="n">x_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">x_hat</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">loss</span>

  <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
      <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">optimizer</span>
</code></pre></div> </div> <h2 id="定义训练集"> <a href="#定义训练集" class="anchor-heading" aria-labelledby="定义训练集"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 定义训练集 </h2> <p>定义pytorch的<code class="language-plaintext highlighter-rouge">DataLoader</code></p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dataset</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">())</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</code></pre></div> </div> <h2 id="模型训练-2"> <a href="#模型训练-2" class="anchor-heading" aria-labelledby="模型训练-2"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 模型训练 </h2> <p>使用<code class="language-plaintext highlighter-rouge">Trainer</code>训练模型</p> </li> </ul> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># model
</span><span class="n">autoencoder</span> <span class="o">=</span> <span class="n">LitAutoEncoder</span><span class="p">(</span><span class="n">Encoder</span><span class="p">(),</span> <span class="n">Decoder</span><span class="p">())</span>

<span class="c1"># train model
</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="p">.</span><span class="n">Trainer</span><span class="p">()</span>
<span class="n">trainer</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">autoencoder</span><span class="p">,</span> <span class="n">train_dataloaders</span><span class="o">=</span><span class="n">train_loader</span><span class="p">)</span>
</code></pre></div></div> <h2 id="干掉训练循环"> <a href="#干掉训练循环" class="anchor-heading" aria-labelledby="干掉训练循环"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 干掉训练循环 </h2> <p><code class="language-plaintext highlighter-rouge">Trainer</code>在背地里为我们做了以下事情:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">autoencoder</span> <span class="o">=</span> <span class="n">LitAutoEncoder</span><span class="p">(</span><span class="n">Encoder</span><span class="p">(),</span> <span class="n">Decoder</span><span class="p">())</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="p">.</span><span class="n">configure_optimizers</span><span class="p">()</span>

<span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="p">.</span><span class="n">training_step</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">)</span>

    <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
</code></pre></div></div> <h1 id="添加验证集和测试集"> <a href="#添加验证集和测试集" class="anchor-heading" aria-labelledby="添加验证集和测试集"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 添加验证集和测试集 </h1> <p>为了确保模型在未见过的数据集上也能使用，数据集一般会分成训练集和测试集，测试集在训练阶段不使用。</p> <h2 id="分割数据集"> <a href="#分割数据集" class="anchor-heading" aria-labelledby="分割数据集"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 分割数据集 </h2> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch.utils.data</span> <span class="k">as</span> <span class="n">data</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="n">transforms</span>

<span class="c1"># Load data sets
</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">()</span>
<span class="n">train_set</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s">"MNIST"</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
<span class="n">test_set</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s">"MNIST"</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
</code></pre></div></div> <h2 id="定义测试循环"> <a href="#定义测试循环" class="anchor-heading" aria-labelledby="定义测试循环"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 定义测试循环 </h2> <p>实现<code class="language-plaintext highlighter-rouge">test_step</code>方法，</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LitAutoEncoder</span><span class="p">(</span><span class="n">pl</span><span class="p">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="p">...</span>

    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="c1"># this is the test loop
</span>        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">test_loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">x_hat</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="s">"test_loss"</span><span class="p">,</span> <span class="n">test_loss</span><span class="p">)</span>
</code></pre></div></div> <h2 id="训练之后加入测试步骤"> <a href="#训练之后加入测试步骤" class="anchor-heading" aria-labelledby="训练之后加入测试步骤"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 训练之后加入测试步骤 </h2> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="c1"># initialize the Trainer
</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">()</span>

<span class="c1"># test the model
</span><span class="n">trainer</span><span class="p">.</span><span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloaders</span><span class="o">=</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_set</span><span class="p">))</span>
</code></pre></div></div> <h2 id="添加验证循环"> <a href="#添加验证循环" class="anchor-heading" aria-labelledby="添加验证循环"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 添加验证循环 </h2> <p>在训练集中分出一部分作为验证集</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># use 20% of training data for validation
</span><span class="n">train_set_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>
<span class="n">valid_set_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span> <span class="o">-</span> <span class="n">train_set_size</span>

<span class="c1"># split the train set into two
</span><span class="n">seed</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">Generator</span><span class="p">().</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">train_set</span><span class="p">,</span> <span class="n">valid_set</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">random_split</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="p">[</span><span class="n">train_set_size</span><span class="p">,</span> <span class="n">valid_set_size</span><span class="p">],</span> <span class="n">generator</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
</code></pre></div></div> <p>添加<code class="language-plaintext highlighter-rouge">validation_step</code></p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LitAutoEncoder</span><span class="p">(</span><span class="n">pl</span><span class="p">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="p">...</span>

    <span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="c1"># this is the validation loop
</span>        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">x_hat</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="s">"val_loss"</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">)</span>
</code></pre></div></div> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span>
<span class="n">valid_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_set</span><span class="p">)</span>

<span class="c1"># train with both splits
</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">()</span>
<span class="n">trainer</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">valid_loader</span><span class="p">)</span>
</code></pre></div></div> <h1 id="保存模型过程"> <a href="#保存模型过程" class="anchor-heading" aria-labelledby="保存模型过程"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 保存模型过程 </h1> <p>lightning的checkpoint包含以下内容:</p> <ul> <li>16-bit scaling factor (if using 16-bit precision training)</li> <li>Current epoch</li> <li>Global step</li> <li>LightningModule’s state_dict</li> <li>State of all optimizers</li> <li>State of all learning rate schedulers</li> <li>State of all callbacks (for stateful callbacks)</li> <li>State of datamodule (for stateful datamodules)</li> <li>The hyperparameters (init arguments) with which the model was created</li> <li>The hyperparameters (init arguments) with which the datamodule was created</li> <li>State of Loops</li> </ul> <h2 id="保存ckpt"> <a href="#保存ckpt" class="anchor-heading" aria-labelledby="保存ckpt"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 保存ckpt </h2> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># saves checkpoints to 'some/path/' at every epoch end
</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">default_root_dir</span><span class="o">=</span><span class="s">"some/path/"</span><span class="p">)</span>
</code></pre></div></div> <h2 id="加载"> <a href="#加载" class="anchor-heading" aria-labelledby="加载"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 加载 </h2> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="p">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="s">"/path/to/checkpoint.ckpt"</span><span class="p">)</span>

<span class="c1"># disable randomness, dropout, etc...
</span><span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>

<span class="c1"># predict with the model
</span><span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div> <p>超参数保存：</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MyLightningModule</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">another_parameter</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
</code></pre></div></div> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="k">lambda</span> <span class="n">storage</span><span class="p">,</span> <span class="n">loc</span><span class="p">:</span> <span class="n">storage</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s">"hyper_parameters"</span><span class="p">])</span>
<span class="c1"># {"learning_rate": the_value, "another_parameter": the_other_value}
</span></code></pre></div></div> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="p">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="s">"/path/to/checkpoint.ckpt"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">learning_rate</span><span class="p">)</span>
</code></pre></div></div> <p>使用其他参数初始化:</p> <p>如果初始化<code class="language-plaintext highlighter-rouge">LightningModule</code>时使用了<code class="language-plaintext highlighter-rouge">self.save_hyperparameters()</code>，可以使用不同的超参数初始化模型。</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># if you train and save the model like this it will use these values when loading
# the weights. But you can overwrite this
</span><span class="n">LitModel</span><span class="p">(</span><span class="n">in_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># uses in_dim=32, out_dim=10
</span><span class="n">model</span> <span class="o">=</span> <span class="n">LitModel</span><span class="p">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span>

<span class="c1"># uses in_dim=128, out_dim=10
</span><span class="n">model</span> <span class="o">=</span> <span class="n">LitModel</span><span class="p">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="n">PATH</span><span class="p">,</span> <span class="n">in_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div> <h2 id="nnmodule-from-checkpoint"> <a href="#nnmodule-from-checkpoint" class="anchor-heading" aria-labelledby="nnmodule-from-checkpoint"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> nn.Module from checkpoint </h2> <p>lightning的ckpt和torch原生的<code class="language-plaintext highlighter-rouge">nn.Modules</code>完全匹配。</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">CKPT_PATH</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">.</span><span class="n">keys</span><span class="p">())</span>
</code></pre></div></div> <p>假设创建了<code class="language-plaintext highlighter-rouge">LightningModule</code></p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="p">...</span>


<span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="p">...</span>


<span class="k">class</span> <span class="nc">Autoencoder</span><span class="p">(</span><span class="n">pl</span><span class="p">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="p">...</span>


<span class="n">autoencoder</span> <span class="o">=</span> <span class="n">Autoencoder</span><span class="p">(</span><span class="n">Encoder</span><span class="p">(),</span> <span class="n">Decoder</span><span class="p">())</span>
</code></pre></div></div> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">CKPT_PATH</span><span class="p">)</span>
<span class="n">encoder_weights</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s">"encoder"</span><span class="p">]</span>
<span class="n">decoder_weights</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s">"decoder"</span><span class="p">]</span>
</code></pre></div></div> <h2 id="禁用ckpt"> <a href="#禁用ckpt" class="anchor-heading" aria-labelledby="禁用ckpt"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 禁用ckpt </h2> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">enable_checkpointing</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div> <h2 id="恢复训练"> <a href="#恢复训练" class="anchor-heading" aria-labelledby="恢复训练"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 恢复训练 </h2> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">LitModel</span><span class="p">()</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">()</span>

<span class="c1"># automatically restores model, epoch, step, LR schedulers, etc...
</span><span class="n">trainer</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="o">=</span><span class="s">"some/path/to/my_checkpoint.ckpt"</span><span class="p">)</span>
</code></pre></div></div> <h1 id="提前终止训练"> <a href="#提前终止训练" class="anchor-heading" aria-labelledby="提前终止训练"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 提前终止训练 </h1> <p>重写<code class="language-plaintext highlighter-rouge">on_train_batch_start()</code>来提前终止训练。</p> <p><code class="language-plaintext highlighter-rouge">EarlyStopping</code> 回调函数可以监控一个metric并在模型训练没有提升的时候提前终止，启用这个功能使用以下过程:</p> <ul> <li> <p>Import EarlyStopping callback.</p> </li> <li> <p>Log the metric you want to monitor using log() method.</p> </li> <li> <p>Init the callback, and set monitor to the logged metric of your choice.</p> </li> <li> <p>Set the mode based on the metric needs to be monitored.</p> </li> <li> <p>Pass the EarlyStopping callback to the Trainer callbacks flag.</p> </li> </ul> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">lightning.pytorch.callbacks.early_stopping</span> <span class="kn">import</span> <span class="n">EarlyStopping</span>


<span class="k">class</span> <span class="nc">LitModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="p">...</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="s">"val_loss"</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">LitModel</span><span class="p">()</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s">"val_loss"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">"min"</span><span class="p">)])</span>
<span class="n">trainer</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div></div> <p>可以自定义callback的行为:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">early_stop_callback</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s">"val_accuracy"</span><span class="p">,</span> <span class="n">min_delta</span><span class="o">=</span><span class="mf">0.00</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">"max"</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">early_stop_callback</span><span class="p">])</span>
</code></pre></div></div> <p>一些其他的参数:</p> <ul> <li> <p>stopping_threshold: Stops training immediately once the monitored quantity reaches this threshold. It is useful when we know that going beyond a certain optimal value does not further benefit us.</p> </li> <li> <p>divergence_threshold: Stops training as soon as the monitored quantity becomes worse than this threshold. When reaching a value this bad, we believes the model cannot recover anymore and it is better to stop early and run with different initial conditions.</p> </li> <li> <p>check_finite: When turned on, it stops training if the monitored metric becomes NaN or infinite.</p> </li> <li> <p>check_on_train_epoch_end: When turned on, it checks the metric at the end of a training epoch. Use this only when you are monitoring any metric logged within training-specific hooks on epoch-level.</p> </li> </ul> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MyEarlyStopping</span><span class="p">(</span><span class="n">EarlyStopping</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">on_validation_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">pl_module</span><span class="p">):</span>
        <span class="c1"># override this to disable early stopping at the end of val loop
</span>        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">pl_module</span><span class="p">):</span>
        <span class="c1"># instead, do it at the end of training loop
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">_run_early_stopping_check</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
</code></pre></div></div> <p class="note">The <code class="language-plaintext highlighter-rouge">EarlyStopping</code> callback runs at the end of every validation epoch by default. However, the frequency of validation can be modified by setting various parameters in the <code class="language-plaintext highlighter-rouge">Trainer</code>, for example <code class="language-plaintext highlighter-rouge">check_val_every_n_epoch</code> and <code class="language-plaintext highlighter-rouge">val_check_interval</code>. It must be noted that the patience parameter counts the number of validation checks with no improvement, and not the number of training epochs. Therefore, with parameters <code class="language-plaintext highlighter-rouge">check_val_every_n_epoch=10</code> and <code class="language-plaintext highlighter-rouge">patience=3</code>, the trainer will perform at least 40 training epochs before being stopped.</p> <h1 id="迁移学习"> <a href="#迁移学习" class="anchor-heading" aria-labelledby="迁移学习"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 迁移学习 </h1> <h2 id="使用预训练的lightningmodule"> <a href="#使用预训练的lightningmodule" class="anchor-heading" aria-labelledby="使用预训练的lightningmodule"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 使用预训练的<code class="language-plaintext highlighter-rouge">LightningModule</code> </h2> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="p">...</span>


<span class="k">class</span> <span class="nc">AutoEncoder</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">()</span>


<span class="k">class</span> <span class="nc">CIFAR10Classifier</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># init the pretrained LightningModule
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">feature_extractor</span> <span class="o">=</span> <span class="n">AutoEncoder</span><span class="p">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">feature_extractor</span><span class="p">.</span><span class="n">freeze</span><span class="p">()</span>

        <span class="c1"># the autoencoder outputs a 100-dim representation and CIFAR-10 has 10 classes
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">representations</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">feature_extractor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">representations</span><span class="p">)</span>
        <span class="p">...</span>
</code></pre></div></div> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="n">models</span>


<span class="k">class</span> <span class="nc">ImagenetTransferLearning</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>

        <span class="c1"># init a pretrained resnet
</span>        <span class="n">backbone</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="n">resnet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s">"DEFAULT"</span><span class="p">)</span>
        <span class="n">num_filters</span> <span class="o">=</span> <span class="n">backbone</span><span class="p">.</span><span class="n">fc</span><span class="p">.</span><span class="n">in_features</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">backbone</span><span class="p">.</span><span class="n">children</span><span class="p">())[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">feature_extractor</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

        <span class="c1"># use the pretrained model to classify cifar-10 (10 image classes)
</span>        <span class="n">num_target_classes</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_filters</span><span class="p">,</span> <span class="n">num_target_classes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">feature_extractor</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">representations</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">feature_extractor</span><span class="p">(</span><span class="n">x</span><span class="p">).</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">representations</span><span class="p">)</span>
        <span class="p">...</span>
</code></pre></div></div> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">ImagenetTransferLearning</span><span class="p">()</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">()</span>
<span class="n">trainer</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div></div> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">ImagenetTransferLearning</span><span class="p">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">freeze</span><span class="p">()</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">some_images_from_cifar10</span><span class="p">()</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div> <h2 id="bert"> <a href="#bert" class="anchor-heading" aria-labelledby="bert"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Bert </h2> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">BertMNLIFinetuner</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">bert</span> <span class="o">=</span> <span class="n">BertModel</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">"bert-base-cased"</span><span class="p">,</span> <span class="n">output_attentions</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">bert</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">3</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="p">):</span>
        <span class="n">h</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bert</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">)</span>

        <span class="n">h_cls</span> <span class="o">=</span> <span class="n">h</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">W</span><span class="p">(</span><span class="n">h_cls</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span><span class="p">,</span> <span class="n">attn</span>
</code></pre></div></div> <h1 id="命令行中配置超参数"> <a href="#命令行中配置超参数" class="anchor-heading" aria-labelledby="命令行中配置超参数"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 命令行中配置超参数 </h1> <h2 id="argumentparser"> <a href="#argumentparser" class="anchor-heading" aria-labelledby="argumentparser"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> ArgumentParser </h2> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">ArgumentParser</span>

<span class="n">parser</span> <span class="o">=</span> <span class="n">ArgumentParser</span><span class="p">()</span>

<span class="c1"># Trainer arguments
</span><span class="n">parser</span><span class="p">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">"--devices"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Hyperparameters for the model
</span><span class="n">parser</span><span class="p">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">"--layer_1_dim"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>

<span class="c1"># Parse the user inputs and defaults (returns a argparse.Namespace)
</span><span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="p">.</span><span class="n">parse_args</span><span class="p">()</span>

<span class="c1"># Use the parsed arguments in your program
</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">devices</span><span class="o">=</span><span class="n">args</span><span class="p">.</span><span class="n">devices</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">(</span><span class="n">layer_1_dim</span><span class="o">=</span><span class="n">args</span><span class="p">.</span><span class="n">layer_1_dim</span><span class="p">)</span>
</code></pre></div></div> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python trainer.py <span class="nt">--layer_1_dim</span> 64 <span class="nt">--devices</span> 1
</code></pre></div></div> <h2 id="lightning-cli"> <a href="#lightning-cli" class="anchor-heading" aria-labelledby="lightning-cli"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://lightning.ai/docs/pytorch/stable/cli/lightning_cli.html">lightning cli</a> </h2> <h1 id="debug可视化以及寻找瓶颈"> <a href="#debug可视化以及寻找瓶颈" class="anchor-heading" aria-labelledby="debug可视化以及寻找瓶颈"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> debug,可视化以及寻找瓶颈 </h1> <h2 id="debug"> <a href="#debug" class="anchor-heading" aria-labelledby="debug"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> debug </h2> <h3 id="设置断点"> <a href="#设置断点" class="anchor-heading" aria-labelledby="设置断点"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 设置断点 </h3> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">function_to_debug</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="mi">2</span>

    <span class="c1"># set breakpoint
</span>    <span class="kn">import</span> <span class="nn">pdb</span>

    <span class="n">pdb</span><span class="p">.</span><span class="n">set_trace</span><span class="p">()</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span>
</code></pre></div></div> <h3 id="跑一遍代码"> <a href="#跑一遍代码" class="anchor-heading" aria-labelledby="跑一遍代码"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 跑一遍代码 </h3> <p><code class="language-plaintext highlighter-rouge">fast_dev_run</code>会跑5个batch的训练验证和预测</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Trainer</span><span class="p">(</span><span class="n">fast_dev_run</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div> <div class="language-py note highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Trainer</span><span class="p">(</span><span class="n">fast_dev_run</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
</code></pre></div></div> <p>This argument will disable tuner, checkpoint callbacks, early stopping callbacks, loggers and logger callbacks like <code class="language-plaintext highlighter-rouge">LearningRateMonitor</code> and <code class="language-plaintext highlighter-rouge">DeviceStatsMonitor</code>.</p> <h3 id="缩短epoch长度"> <a href="#缩短epoch长度" class="anchor-heading" aria-labelledby="缩短epoch长度"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 缩短epoch长度 </h3> <p>比如使用20%数据集作为训练，1%数据集作为验证</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># use only 10% of training data and 1% of val data
</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">limit_train_batches</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">limit_val_batches</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="c1"># use 10 batches of train and 5 batches of val
</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">limit_train_batches</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">limit_val_batches</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div> <h3 id="简单检查"> <a href="#简单检查" class="anchor-heading" aria-labelledby="简单检查"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 简单检查 </h3> <p>在训练开始的时候进行两步验证。</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">num_sanity_val_steps</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div> <h3 id="显示lightningmodule权重summary"> <a href="#显示lightningmodule权重summary" class="anchor-heading" aria-labelledby="显示lightningmodule权重summary"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 显示<code class="language-plaintext highlighter-rouge">LightningModule</code>权重summary </h3> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trainer</span><span class="p">.</span><span class="n">fit</span><span class="p">(...)</span>
</code></pre></div></div> <p>要给子模块添加summary,使用:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">lightning.pytorch.callbacks</span> <span class="kn">import</span> <span class="n">ModelSummary</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">ModelSummary</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=-</span><span class="mi">1</span><span class="p">)])</span>
</code></pre></div></div> <p>不调用<code class="language-plaintext highlighter-rouge">.fit</code>的情况下打印summary:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">lightning.pytorch.utilities.model_summary</span> <span class="kn">import</span> <span class="n">ModelSummary</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LitModel</span><span class="p">()</span>
<span class="n">summary</span> <span class="o">=</span> <span class="n">ModelSummary</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">summary</span><span class="p">)</span>
</code></pre></div></div> <p>关闭功能使用:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Trainer</span><span class="p">(</span><span class="n">enable_model_summary</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div> <h3 id="查找代码瓶颈"> <a href="#查找代码瓶颈" class="anchor-heading" aria-labelledby="查找代码瓶颈"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 查找代码瓶颈 </h3> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">profiler</span><span class="o">=</span><span class="s">"simple"</span><span class="p">)</span>
</code></pre></div></div> <p>要查看每个函数的运行时间，使用：</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">profiler</span><span class="o">=</span><span class="s">"advanced"</span><span class="p">)</span>
</code></pre></div></div> <p>输出到文件中:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">lightning.pytorch.profilers</span> <span class="kn">import</span> <span class="n">AdvancedProfiler</span>

<span class="n">profiler</span> <span class="o">=</span> <span class="n">AdvancedProfiler</span><span class="p">(</span><span class="n">dirpath</span><span class="o">=</span><span class="s">"."</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s">"perf_logs"</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">profiler</span><span class="o">=</span><span class="n">profiler</span><span class="p">)</span>
</code></pre></div></div> <p>查看加速器效果:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">lightning.pytorch.callbacks</span> <span class="kn">import</span> <span class="n">DeviceStatsMonitor</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">DeviceStatsMonitor</span><span class="p">()])</span>
</code></pre></div></div> <p>CPU metrics will be tracked by default on the CPU accelerator. To enable it for other accelerators set <code class="language-plaintext highlighter-rouge">DeviceStatsMonitor(cpu_stats=True)</code>. To disable logging CPU metrics, you can specify <code class="language-plaintext highlighter-rouge">DeviceStatsMonitor(cpu_stats=False)</code>.</p> <h3 id="实验跟踪和可视化"> <a href="#实验跟踪和可视化" class="anchor-heading" aria-labelledby="实验跟踪和可视化"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 实验跟踪和可视化 </h3> <h4 id="metrics跟踪"> <a href="#metrics跟踪" class="anchor-heading" aria-labelledby="metrics跟踪"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> metrics跟踪 </h4> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LitModel</span><span class="p">(</span><span class="n">pl</span><span class="p">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">value</span> <span class="o">=</span> <span class="p">...</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="s">"some_value"</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
</code></pre></div></div> <p>使用<code class="language-plaintext highlighter-rouge">self.log</code>方法.</p> <p>记录多个metrics,使用:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">values</span> <span class="o">=</span> <span class="p">{</span><span class="s">"loss"</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s">"acc"</span><span class="p">:</span> <span class="n">acc</span><span class="p">,</span> <span class="s">"metric_n"</span><span class="p">:</span> <span class="n">metric_n</span><span class="p">}</span>  <span class="c1"># add more items if needed
</span><span class="bp">self</span><span class="p">.</span><span class="n">log_dict</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
</code></pre></div></div> <p>要在进度条里查看使用，</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="bp">self</span><span class="p">.</span><span class="n">log</span><span class="p">(...,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div> <p>浏览器中查看，略</p> <p>metric积累，略</p> <p>目录保存：</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Trainer</span><span class="p">(</span><span class="n">default_root_dir</span><span class="o">=</span><span class="s">"/your/custom/path"</span><span class="p">)</span>
</code></pre></div></div> <h1 id="模型推理"> <a href="#模型推理" class="anchor-heading" aria-labelledby="模型推理"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 模型推理 </h1> <h2 id="产品级部署-1"> <a href="#产品级部署-1" class="anchor-heading" aria-labelledby="产品级部署-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 产品级部署-1 </h2> <h3 id="加载ckpt并预测"> <a href="#加载ckpt并预测" class="anchor-heading" aria-labelledby="加载ckpt并预测"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 加载ckpt并预测 </h3> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">LitModel</span><span class="p">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="s">"best_model.ckpt"</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div> <h3 id="lightningmodule添加预测过程"> <a href="#lightningmodule添加预测过程" class="anchor-heading" aria-labelledby="lightningmodule添加预测过程"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <code class="language-plaintext highlighter-rouge">LightningModule</code>添加预测过程 </h3> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">predict_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</code></pre></div></div> <p>把dataloader加载到trainer</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(...)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">()</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">trainer</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">)</span>
</code></pre></div></div> <h3 id="添加复杂的推理逻辑"> <a href="#添加复杂的推理逻辑" class="anchor-heading" aria-labelledby="添加复杂的推理逻辑"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 添加复杂的推理逻辑 </h3> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LitMCdropoutModel</span><span class="p">(</span><span class="n">pl</span><span class="p">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">mc_iteration</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">mc_iteration</span> <span class="o">=</span> <span class="n">mc_iteration</span>

    <span class="k">def</span> <span class="nf">predict_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="c1"># enable Monte Carlo Dropout
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>

        <span class="c1"># take average of `self.mc_iteration` iterations
</span>        <span class="n">pred</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">mc_iteration</span><span class="p">)]</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">pred</span><span class="p">).</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pred</span>
</code></pre></div></div> <h3 id="使用分布式推理"> <a href="#使用分布式推理" class="anchor-heading" aria-labelledby="使用分布式推理"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 使用分布式推理 </h3> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">lightning.pytorch.callbacks</span> <span class="kn">import</span> <span class="n">BasePredictionWriter</span>


<span class="k">class</span> <span class="nc">CustomWriter</span><span class="p">(</span><span class="n">BasePredictionWriter</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">,</span> <span class="n">write_interval</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">(</span><span class="n">write_interval</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">output_dir</span> <span class="o">=</span> <span class="n">output_dir</span>

    <span class="k">def</span> <span class="nf">write_on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">pl_module</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">batch_indices</span><span class="p">):</span>
        <span class="c1"># this will create N (num processes) files in `output_dir` each containing
</span>        <span class="c1"># the predictions of it's respective rank
</span>        <span class="n">torch</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s">"predictions_</span><span class="si">{</span><span class="n">trainer</span><span class="p">.</span><span class="n">global_rank</span><span class="si">}</span><span class="s">.pt"</span><span class="p">))</span>

        <span class="c1"># optionally, you can also save `batch_indices` to get the information about the data index
</span>        <span class="c1"># from your prediction data
</span>        <span class="n">torch</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">batch_indices</span><span class="p">,</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s">"batch_indices_</span><span class="si">{</span><span class="n">trainer</span><span class="p">.</span><span class="n">global_rank</span><span class="si">}</span><span class="s">.pt"</span><span class="p">))</span>


<span class="c1"># or you can set `writer_interval="batch"` and override `write_on_batch_end` to save
# predictions at batch level
</span><span class="n">pred_writer</span> <span class="o">=</span> <span class="n">CustomWriter</span><span class="p">(</span><span class="n">output_dir</span><span class="o">=</span><span class="s">"pred_path"</span><span class="p">,</span> <span class="n">write_interval</span><span class="o">=</span><span class="s">"epoch"</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">accelerator</span><span class="o">=</span><span class="s">"gpu"</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s">"ddp"</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">pred_writer</span><span class="p">])</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BoringModel</span><span class="p">()</span>
<span class="n">trainer</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">return_predictions</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div> <h2 id="产品级部署-2"> <a href="#产品级部署-2" class="anchor-heading" aria-labelledby="产品级部署-2"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 产品级部署-2 </h2> <h3 id="使用pytorch"> <a href="#使用pytorch" class="anchor-heading" aria-labelledby="使用pytorch"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 使用pytorch </h3> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>


<span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="p">...</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">"path/to/lightning/checkpoint.ckpt"</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s">"state_dict"</span><span class="p">])</span>
<span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
</code></pre></div></div> <h3 id="从lightning中提取nnmodules"> <a href="#从lightning中提取nnmodules" class="anchor-heading" aria-labelledby="从lightning中提取nnmodules"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 从lightning中提取<code class="language-plaintext highlighter-rouge">nn.Modules</code> </h3> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="p">...</span>


<span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="p">...</span>


<span class="k">class</span> <span class="nc">AutoEncoderProd</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">AutoEncoderSystem</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">auto_encoder</span> <span class="o">=</span> <span class="n">AutoEncoderProd</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">auto_encoder</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">auto_encoder</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">auto_encoder</span><span class="p">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="p">...</span>
        <span class="k">return</span> <span class="n">loss</span>


<span class="c1"># train it
</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">devices</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">accelerator</span><span class="o">=</span><span class="s">"gpu"</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s">"ddp"</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoEncoderSystem</span><span class="p">()</span>
<span class="n">trainer</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">val_dataloader</span><span class="p">)</span>
<span class="n">trainer</span><span class="p">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="s">"best_model.ckpt"</span><span class="p">)</span>


<span class="c1"># create the PyTorch model and load the checkpoint weights
</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoEncoderProd</span><span class="p">()</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">"best_model.ckpt"</span><span class="p">)</span>
<span class="n">hyper_parameters</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s">"hyper_parameters"</span><span class="p">]</span>

<span class="c1"># if you want to restore any hyperparameters, you can pass them too
</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoEncoderProd</span><span class="p">(</span><span class="o">**</span><span class="n">hyper_parameters</span><span class="p">)</span>

<span class="n">model_weights</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s">"state_dict"</span><span class="p">]</span>

<span class="c1"># update keys by dropping `auto_encoder.`
</span><span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">model_weights</span><span class="p">):</span>
    <span class="n">model_weights</span><span class="p">[</span><span class="n">key</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">"auto_encoder."</span><span class="p">,</span> <span class="s">""</span><span class="p">)]</span> <span class="o">=</span> <span class="n">model_weights</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

<span class="n">model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_weights</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div> <h1 id="gpu训练"> <a href="#gpu训练" class="anchor-heading" aria-labelledby="gpu训练"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> GPU训练 </h1> <h2 id="代码修改"> <a href="#代码修改" class="anchor-heading" aria-labelledby="代码修改"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 代码修改 </h2> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># before lightning
</span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">cuda</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">layer_1</span><span class="p">.</span><span class="n">cuda</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">x_hat</span> <span class="o">=</span> <span class="n">layer_1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="c1"># after lightning
</span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">x_hat</span> <span class="o">=</span> <span class="n">layer_1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div> <p>使用<code class="language-plaintext highlighter-rouge">tensor.to</code>和<code class="language-plaintext highlighter-rouge">register_buffer</code></p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># before lightning
</span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="p">.</span><span class="n">cuda</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>


<span class="c1"># with lightning
</span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">LightningModule</code>知道自己处在哪个设备上，使用<code class="language-plaintext highlighter-rouge">self.device</code>. 有时需要把tensor存储为模块属性。但是如果它们不是参数仍然会存在cpu上，将这个tensor注册为buffer使用<code class="language-plaintext highlighter-rouge">register_buffer()</code>.</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LitModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="p">...</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s">"sigma"</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
        <span class="c1"># you can now access self.sigma anywhere in your module
</span></code></pre></div></div> <h3 id="remove-samplers"> <a href="#remove-samplers" class="anchor-heading" aria-labelledby="remove-samplers"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Remove samplers </h3> <p>sampler是自动处理的。</p> <h3 id="同步"> <a href="#同步" class="anchor-heading" aria-labelledby="同步"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 同步 </h3> <p>在分布式模式下必须保证验证和测试step的logging调用在进程间同步，可以给<code class="language-plaintext highlighter-rouge">self.log</code>添加<code class="language-plaintext highlighter-rouge">sync_dist=True</code>，这在下游的任务比如测试最好的ckpt比较重要。 如果使用内建的metric或者使用<code class="language-plaintext highlighter-rouge">TorchMetrics</code>自定义metric会进行自动的处理更新。</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">loss</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="c1"># Add sync_dist=True to sync logging across all GPU workers (may have performance impact)
</span>    <span class="bp">self</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="s">"validation_loss"</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">on_step</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">on_epoch</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">sync_dist</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">loss</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="c1"># Add sync_dist=True to sync logging across all GPU workers (may have performance impact)
</span>    <span class="bp">self</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="s">"test_loss"</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">on_step</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">on_epoch</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">sync_dist</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div> <p>It is possible to perform some computation manually and log the reduced result on rank 0 as follows:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>


<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="n">tensors</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">outputs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tensors</span>


<span class="k">def</span> <span class="nf">on_test_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">all_gather</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">outputs</span><span class="p">))</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">outputs</span><span class="p">.</span><span class="n">clear</span><span class="p">()</span>  <span class="c1"># free memory
</span>
    <span class="c1"># When logging only on rank 0, don't forget to add
</span>    <span class="c1"># `rank_zero_only=True` to avoid deadlocks on synchronization.
</span>    <span class="c1"># caveat: monitoring this is unimplemented. see https://github.com/Lightning-AI/lightning/issues/15852
</span>    <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">trainer</span><span class="p">.</span><span class="n">is_global_zero</span><span class="p">:</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="s">"my_reduced_metric"</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">rank_zero_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div> <h3 id="pickleable-model"> <a href="#pickleable-model" class="anchor-heading" aria-labelledby="pickleable-model"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> pickleable model </h3> <p>在并行模式下可能出现以下错误:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>self._launch(process_obj)
File "/net/software/local/python/3.6.5/lib/python3.6/multiprocessing/popen_spawn_posix.py", line 47,
in _launch reduction.dump(process_obj, fp)
File "/net/software/local/python/3.6.5/lib/python3.6/multiprocessing/reduction.py", line 60, in dump
ForkingPickler(file, protocol).dump(obj)
_pickle.PicklingError: Can't pickle &lt;function &lt;lambda&gt; at 0x2b599e088ae8&gt;:
attribute lookup &lt;lambda&gt; on __main__ failed
</code></pre></div></div> <p>这表明并行模式下模型，优化器,dataloader…中存在无法保存的东西，这是由pytorch限制的。</p> <h2 id="gpu训练-1"> <a href="#gpu训练-1" class="anchor-heading" aria-labelledby="gpu训练-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> gpu训练 </h2> <p>默认情况下会尽可能在gpu上进行训练:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># run on as many GPUs as available by default
</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">accelerator</span><span class="o">=</span><span class="s">"auto"</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="s">"auto"</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s">"auto"</span><span class="p">)</span>
<span class="c1"># equivalent to
</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">()</span>

<span class="c1"># run on one GPU
</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">accelerator</span><span class="o">=</span><span class="s">"gpu"</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># run on multiple GPUs
</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">accelerator</span><span class="o">=</span><span class="s">"gpu"</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="c1"># choose the number of devices automatically
</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">accelerator</span><span class="o">=</span><span class="s">"gpu"</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="s">"auto"</span><span class="p">)</span>
</code></pre></div></div> <p class="note">Setting accelerator=”gpu” will also automatically choose the “mps” device on Apple sillicon GPUs. If you want to avoid this, you can set accelerator=”cuda” instead.</p> <p>可以选择gpu设备</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># DEFAULT (int) specifies how many GPUs to use per node
</span><span class="n">Trainer</span><span class="p">(</span><span class="n">accelerator</span><span class="o">=</span><span class="s">"gpu"</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>

<span class="c1"># Above is equivalent to
</span><span class="n">Trainer</span><span class="p">(</span><span class="n">accelerator</span><span class="o">=</span><span class="s">"gpu"</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">)))</span>

<span class="c1"># Specify which GPUs to use (don't use when running on cluster)
</span><span class="n">Trainer</span><span class="p">(</span><span class="n">accelerator</span><span class="o">=</span><span class="s">"gpu"</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="c1"># Equivalent using a string
</span><span class="n">Trainer</span><span class="p">(</span><span class="n">accelerator</span><span class="o">=</span><span class="s">"gpu"</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="s">"0, 1"</span><span class="p">)</span>

<span class="c1"># To use all available GPUs put -1 or '-1'
# equivalent to list(range(torch.cuda.device_count()))
</span><span class="n">Trainer</span><span class="p">(</span><span class="n">accelerator</span><span class="o">=</span><span class="s">"gpu"</span><span class="p">,</span> <span class="n">devices</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> <p>检测可以使用的gpu设备:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">lightning.pytorch.accelerators</span> <span class="kn">import</span> <span class="n">find_usable_cuda_devices</span>

<span class="c1"># Find two GPUs on the system that are not already occupied
</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">accelerator</span><span class="o">=</span><span class="s">"cuda"</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="n">find_usable_cuda_devices</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>

<span class="kn">from</span> <span class="nn">lightning.fabric.accelerators</span> <span class="kn">import</span> <span class="n">find_usable_cuda_devices</span>

<span class="c1"># Works with Fabric too
</span><span class="n">fabric</span> <span class="o">=</span> <span class="n">Fabric</span><span class="p">(</span><span class="n">accelerator</span><span class="o">=</span><span class="s">"cuda"</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="n">find_usable_cuda_devices</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
</code></pre></div></div> <p>当gpu被设置为<code class="language-plaintext highlighter-rouge">exclusive compute mode</code>时比较有用。</p> <h1 id="项目模块化"> <a href="#项目模块化" class="anchor-heading" aria-labelledby="项目模块化"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 项目模块化 </h1> <h2 id="datamodule"> <a href="#datamodule" class="anchor-heading" aria-labelledby="datamodule"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> datamodule </h2> <iframe width="420" height="315" src="https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/pl_docs/pt_dm_vid.m4v" frameborder="0"></iframe> <p>datamodule是用来处理数据的类。下面是5个步骤:</p> <ol> <li>Download / tokenize / process.</li> <li>Clean and (maybe) save to disk.</li> <li>Load inside Dataset.</li> <li>Apply transforms (rotate, tokenize, etc…).</li> <li>Wrap inside a DataLoader. 然后可以使用:</li> </ol> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">LitClassifier</span><span class="p">()</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">()</span>

<span class="n">imagenet</span> <span class="o">=</span> <span class="n">ImagenetDataModule</span><span class="p">()</span>
<span class="n">trainer</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">imagenet</span><span class="p">)</span>

<span class="n">cifar10</span> <span class="o">=</span> <span class="n">CIFAR10DataModule</span><span class="p">()</span>
<span class="n">trainer</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">cifar10</span><span class="p">)</span>
</code></pre></div></div> <p>datamodule解决了以下几个问题:</p> <ul> <li> <p>what splits did you use?</p> </li> <li> <p>what transforms did you use?</p> </li> <li> <p>what normalization did you use?</p> </li> <li> <p>how did you prepare/tokenize the data?</p> </li> </ul> <p>在pytorch中需要这样写:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># regular PyTorch
</span><span class="n">test_data</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="n">my_path</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">predict_data</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="n">my_path</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="n">my_path</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train_data</span><span class="p">,</span> <span class="n">val_data</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="p">[</span><span class="mi">55000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">])</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="n">predict_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">predict_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</code></pre></div></div> <p>等效的在lightning中:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MNISTDataModule</span><span class="p">(</span><span class="n">pl</span><span class="p">.</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s">"path/to/dir"</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">data_dir</span> <span class="o">=</span> <span class="n">data_dir</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">mnist_test</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">mnist_predict</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">mnist_full</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">mnist_train</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">mnist_val</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">mnist_full</span><span class="p">,</span> <span class="p">[</span><span class="mi">55000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">mnist_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">batch_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">val_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">mnist_val</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">batch_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">mnist_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">batch_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">mnist_predict</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">batch_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">teardown</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="c1"># Used to clean-up when the run is finished
</span>        <span class="p">...</span>
</code></pre></div></div> <p>然后就可以复用:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mnist</span> <span class="o">=</span> <span class="n">MNISTDataModule</span><span class="p">(</span><span class="n">my_path</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LitClassifier</span><span class="p">()</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">()</span>
<span class="n">trainer</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">mnist</span><span class="p">)</span>
</code></pre></div></div> <p>下面是一个更复杂的例子:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">lightning.pytorch</span> <span class="k">as</span> <span class="n">pl</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">random_split</span><span class="p">,</span> <span class="n">DataLoader</span>

<span class="c1"># Note - you must have torchvision installed for this example
</span><span class="kn">from</span> <span class="nn">torchvision.datasets</span> <span class="kn">import</span> <span class="n">MNIST</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>


<span class="k">class</span> <span class="nc">MNISTDataModule</span><span class="p">(</span><span class="n">pl</span><span class="p">.</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s">"./"</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">data_dir</span> <span class="o">=</span> <span class="n">data_dir</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">transforms</span><span class="p">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))])</span>

    <span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># download
</span>        <span class="n">MNIST</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">MNIST</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="c1"># Assign train/val datasets for use in dataloaders
</span>        <span class="k">if</span> <span class="n">stage</span> <span class="o">==</span> <span class="s">"fit"</span><span class="p">:</span>
            <span class="n">mnist_full</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">transform</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">mnist_train</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">mnist_val</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">mnist_full</span><span class="p">,</span> <span class="p">[</span><span class="mi">55000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">])</span>

        <span class="c1"># Assign test dataset for use in dataloader(s)
</span>        <span class="k">if</span> <span class="n">stage</span> <span class="o">==</span> <span class="s">"test"</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">mnist_test</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">transform</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">stage</span> <span class="o">==</span> <span class="s">"predict"</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">mnist_predict</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">transform</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">mnist_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">val_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">mnist_val</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">mnist_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">mnist_predict</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</code></pre></div></div> <p>要定义datamodule需要实现以下方法:</p> <ul> <li>prepare_data (how to download, tokenize, etc…)</li> <li>setup (how to split, define dataset, etc…)</li> <li>train_dataloader</li> <li>val_dataloader</li> <li>test_dataloader</li> <li>predict_dataloader</li> </ul> <h3 id="prepare_data"> <a href="#prepare_data" class="anchor-heading" aria-labelledby="prepare_data"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> prepare_data </h3> <p>用多个进程下载和保存数据可能导致数据冲突，Lightning可以确保<code class="language-plaintext highlighter-rouge">prepare_data()</code>只在cpu的一个进程上调用。对于多节点训练，这个hook取决于<code class="language-plaintext highlighter-rouge">prepare_data_per_node</code>。<code class="language-plaintext highlighter-rouge">setup()</code>会在<code class="language-plaintext highlighter-rouge">prepare_data</code>之后进行调用，there is a barrier in between which ensures that all the processes proceed to setup once the data is prepared and available for use.</p> <ul> <li> <p>download, i.e. download data only once on the disk from a single process</p> </li> <li> <p>tokenize. Since it’s a one time process, it is not recommended to do it on all processes</p> </li> </ul> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MNISTDataModule</span><span class="p">(</span><span class="n">pl</span><span class="p">.</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># download
</span>        <span class="n">MNIST</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">())</span>
        <span class="n">MNIST</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">())</span>
</code></pre></div></div> <p class="warning"><code class="language-plaintext highlighter-rouge">prepare_data</code> is called from the main process. It is not recommended to assign state here (e.g. self.x = y) since it is called on a single process and if you assign states here then they won’t be available for other processes.</p> <h3 id="setup"> <a href="#setup" class="anchor-heading" aria-labelledby="setup"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> setup </h3> <p>有时想要在每块GPU上进行数据操作，使用<code class="language-plaintext highlighter-rouge">setup()</code>:</p> <ul> <li> <p>count number of classes</p> </li> <li> <p>build vocabulary</p> </li> <li> <p>perform train/val/test splits</p> </li> <li> <p>create datasets</p> </li> <li> <p>apply transforms (defined explicitly in your datamodule)</p> </li> </ul> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">lightning.pytorch</span> <span class="k">as</span> <span class="n">pl</span>


<span class="k">class</span> <span class="nc">MNISTDataModule</span><span class="p">(</span><span class="n">pl</span><span class="p">.</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="c1"># Assign Train/val split(s) for use in Dataloaders
</span>        <span class="k">if</span> <span class="n">stage</span> <span class="o">==</span> <span class="s">"fit"</span><span class="p">:</span>
            <span class="n">mnist_full</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">transform</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">mnist_train</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">mnist_val</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">mnist_full</span><span class="p">,</span> <span class="p">[</span><span class="mi">55000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">])</span>

        <span class="c1"># Assign Test split(s) for use in Dataloaders
</span>        <span class="k">if</span> <span class="n">stage</span> <span class="o">==</span> <span class="s">"test"</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">mnist_test</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">transform</span><span class="p">)</span>
</code></pre></div></div> <p>对于NLP可能想要获得文本tooken,可以:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LitDataModule</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_Dataset</span><span class="p">(...)</span>
        <span class="n">train_dataset</span> <span class="o">=</span> <span class="p">...</span>
        <span class="n">val_dataset</span> <span class="o">=</span> <span class="p">...</span>
        <span class="c1"># tokenize
</span>        <span class="c1"># save it to disk
</span>
    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">):</span>
        <span class="c1"># load it back here
</span>        <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset_from_disk</span><span class="p">(...)</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">stage</code>参数用来为trainer设置，trainer.{fit,validate,test,predict}.</p> <blockquote class="note"> <p>setup is called from every process across all the nodes. Setting state here is recommended.</p> <p>teardown can be used to clean up the state. It is also called from every process across all the nodes.</p> </blockquote> <h3 id="train_dataloader"> <a href="#train_dataloader" class="anchor-heading" aria-labelledby="train_dataloader"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> train_dataloader </h3> <p><code class="language-plaintext highlighter-rouge">train_dataloader()</code>方法用来生成训练dataloader.通常只是封装在<code class="language-plaintext highlighter-rouge">setup</code>中封装的dataset. trainer的<code class="language-plaintext highlighter-rouge">fit()</code>方法将会使用这个dataloader.</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">lightning.pytorch</span> <span class="k">as</span> <span class="n">pl</span>

<span class="k">class</span> <span class="nc">MNISTDataModule</span><span class="p">(</span><span class="n">pl</span><span class="p">.</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">mnist_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
</code></pre></div></div> <h3 id="val_dataloader"> <a href="#val_dataloader" class="anchor-heading" aria-labelledby="val_dataloader"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> val_dataloader </h3> <h3 id="test_dataloader"> <a href="#test_dataloader" class="anchor-heading" aria-labelledby="test_dataloader"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> test_dataloader </h3> <h3 id="predict_dataloader"> <a href="#predict_dataloader" class="anchor-heading" aria-labelledby="predict_dataloader"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> predict_dataloader </h3> <h3 id="transfer_batch_to_device"> <a href="#transfer_batch_to_device" class="anchor-heading" aria-labelledby="transfer_batch_to_device"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> transfer_batch_to_device </h3> <h3 id="on_before_batch_transfer"> <a href="#on_before_batch_transfer" class="anchor-heading" aria-labelledby="on_before_batch_transfer"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> on_before_batch_transfer </h3> <h3 id="on_after_batch_transfer"> <a href="#on_after_batch_transfer" class="anchor-heading" aria-labelledby="on_after_batch_transfer"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> on_after_batch_transfer </h3> <h3 id="load_state_dict"> <a href="#load_state_dict" class="anchor-heading" aria-labelledby="load_state_dict"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> load_state_dict </h3> <h3 id="state_dict"> <a href="#state_dict" class="anchor-heading" aria-labelledby="state_dict"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> state_dict </h3> <h3 id="teardown"> <a href="#teardown" class="anchor-heading" aria-labelledby="teardown"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> teardown </h3> <h3 id="prepare_data_per_node"> <a href="#prepare_data_per_node" class="anchor-heading" aria-labelledby="prepare_data_per_node"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> prepare_data_per_node </h3> <h3 id="使用datamodule"> <a href="#使用datamodule" class="anchor-heading" aria-labelledby="使用datamodule"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 使用datamodule </h3> <p>datamodule的使用非常简单:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dm</span> <span class="o">=</span> <span class="n">MNISTDataModule</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">()</span>
<span class="n">trainer</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">=</span><span class="n">dm</span><span class="p">)</span>
<span class="n">trainer</span><span class="p">.</span><span class="n">test</span><span class="p">(</span><span class="n">datamodule</span><span class="o">=</span><span class="n">dm</span><span class="p">)</span>
<span class="n">trainer</span><span class="p">.</span><span class="n">validate</span><span class="p">(</span><span class="n">datamodule</span><span class="o">=</span><span class="n">dm</span><span class="p">)</span>
<span class="n">trainer</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">datamodule</span><span class="o">=</span><span class="n">dm</span><span class="p">)</span>
</code></pre></div></div> <p>如果需要数据集的某些信息才能构建模型，手动运行<code class="language-plaintext highlighter-rouge">prepare_data</code>和<code class="language-plaintext highlighter-rouge">setup</code>:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dm</span> <span class="o">=</span> <span class="n">MNISTDataModule</span><span class="p">()</span>
<span class="n">dm</span><span class="p">.</span><span class="n">prepare_data</span><span class="p">()</span>
<span class="n">dm</span><span class="p">.</span><span class="n">setup</span><span class="p">(</span><span class="n">stage</span><span class="o">=</span><span class="s">"fit"</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="n">dm</span><span class="p">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">dm</span><span class="p">.</span><span class="n">width</span><span class="p">,</span> <span class="n">vocab</span><span class="o">=</span><span class="n">dm</span><span class="p">.</span><span class="n">vocab</span><span class="p">)</span>
<span class="n">trainer</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dm</span><span class="p">)</span>

<span class="n">dm</span><span class="p">.</span><span class="n">setup</span><span class="p">(</span><span class="n">stage</span><span class="o">=</span><span class="s">"test"</span><span class="p">)</span>
<span class="n">trainer</span><span class="p">.</span><span class="n">test</span><span class="p">(</span><span class="n">datamodule</span><span class="o">=</span><span class="n">dm</span><span class="p">)</span>
</code></pre></div></div> <p>You can access the current used datamodule of a trainer via <code class="language-plaintext highlighter-rouge">trainer.datamodule</code> and the current used dataloaders via the trainer properties <code class="language-plaintext highlighter-rouge">train_dataloader()</code>, <code class="language-plaintext highlighter-rouge">val_dataloaders()</code>, <code class="language-plaintext highlighter-rouge">test_dataloaders()</code>, and <code class="language-plaintext highlighter-rouge">predict_dataloaders()</code>.</p> <h3 id="在pytorch中使用datamodules"> <a href="#在pytorch中使用datamodules" class="anchor-heading" aria-labelledby="在pytorch中使用datamodules"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 在pytorch中使用DataModules </h3> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># download, etc...
</span><span class="n">dm</span> <span class="o">=</span> <span class="n">MNISTDataModule</span><span class="p">()</span>
<span class="n">dm</span><span class="p">.</span><span class="n">prepare_data</span><span class="p">()</span>

<span class="c1"># splits/transforms
</span><span class="n">dm</span><span class="p">.</span><span class="n">setup</span><span class="p">(</span><span class="n">stage</span><span class="o">=</span><span class="s">"fit"</span><span class="p">)</span>

<span class="c1"># use data
</span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dm</span><span class="p">.</span><span class="n">train_dataloader</span><span class="p">():</span>
    <span class="p">...</span>

<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dm</span><span class="p">.</span><span class="n">val_dataloader</span><span class="p">():</span>
    <span class="p">...</span>

<span class="n">dm</span><span class="p">.</span><span class="n">teardown</span><span class="p">(</span><span class="n">stage</span><span class="o">=</span><span class="s">"fit"</span><span class="p">)</span>

<span class="c1"># lazy load test data
</span><span class="n">dm</span><span class="p">.</span><span class="n">setup</span><span class="p">(</span><span class="n">stage</span><span class="o">=</span><span class="s">"test"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dm</span><span class="p">.</span><span class="n">test_dataloader</span><span class="p">():</span>
    <span class="p">...</span>

<span class="n">dm</span><span class="p">.</span><span class="n">teardown</span><span class="p">(</span><span class="n">stage</span><span class="o">=</span><span class="s">"test"</span><span class="p">)</span>
</code></pre></div></div> <h3 id="datamodule中的超参数"> <a href="#datamodule中的超参数" class="anchor-heading" aria-labelledby="datamodule中的超参数"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> datamodule中的超参数 </h3> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">lightning.pytorch</span> <span class="k">as</span> <span class="n">pl</span>

<span class="k">class</span> <span class="nc">CustomDataModule</span><span class="p">(</span><span class="n">pl</span><span class="p">.</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># access the saved hyperparameters
</span>        <span class="n">opt</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">hparams</span><span class="p">.</span><span class="n">lr</span><span class="p">)</span>
</code></pre></div></div> <h3 id="保存datamodule-state"> <a href="#保存datamodule-state" class="anchor-heading" aria-labelledby="保存datamodule-state"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 保存datamodule state </h3> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LitDataModule</span><span class="p">(</span><span class="n">pl</span><span class="p">.</span><span class="n">DataModuler</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># track whatever you want here
</span>        <span class="n">state</span> <span class="o">=</span> <span class="p">{</span><span class="s">"current_train_batch_index"</span><span class="p">:</span> <span class="bp">self</span><span class="p">.</span><span class="n">current_train_batch_index</span><span class="p">}</span>
        <span class="k">return</span> <span class="n">state</span>

    <span class="k">def</span> <span class="nf">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">):</span>
        <span class="c1"># restore the state based on what you tracked in (def state_dict)
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">current_train_batch_index</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s">"current_train_batch_index"</span><span class="p">]</span>
</code></pre></div></div> <h2 id="cli中配置超参数-1"> <a href="#cli中配置超参数-1" class="anchor-heading" aria-labelledby="cli中配置超参数-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> CLI中配置超参数-1 </h2> <p><code class="language-plaintext highlighter-rouge">LightningCLI</code>用来减轻CLI实现难度，要使用这个类，需要额外的lightning功能，</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install</span> <span class="s2">"pytorch-lightning[extra]"</span>
</code></pre></div></div> <h3 id="实现cli"> <a href="#实现cli" class="anchor-heading" aria-labelledby="实现cli"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 实现CLI </h3> <p>实例化一个<code class="language-plaintext highlighter-rouge">LightningCLI</code>对象，然后给<code class="language-plaintext highlighter-rouge">LightningModule</code>参数，也可以多给一个<code class="language-plaintext highlighter-rouge">LightningDataModule</code>参数。</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># main.py
</span><span class="kn">from</span> <span class="nn">lightning.pytorch.cli</span> <span class="kn">import</span> <span class="n">LightningCLI</span>

<span class="c1"># simple demo classes for your convenience
</span><span class="kn">from</span> <span class="nn">lightning.pytorch.demos.boring_classes</span> <span class="kn">import</span> <span class="n">DemoModel</span><span class="p">,</span> <span class="n">BoringDataModule</span>


<span class="k">def</span> <span class="nf">cli_main</span><span class="p">():</span>
    <span class="n">cli</span> <span class="o">=</span> <span class="n">LightningCLI</span><span class="p">(</span><span class="n">DemoModel</span><span class="p">,</span> <span class="n">BoringDataModule</span><span class="p">)</span>
    <span class="c1"># note: don't call fit!!
</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">cli_main</span><span class="p">()</span>
    <span class="c1"># note: it is good practice to implement the CLI in a function and call it in the main if block
</span></code></pre></div></div> <p>现在模型可以通过CLI管理:</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python main.py <span class="nt">--help</span>
</code></pre></div></div> <p>会输出:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>usage: main.py [-h] [-c CONFIG] [--print_config [={comments,skip_null,skip_default}+]]
        {fit,validate,test,predict,tune} ...

pytorch-lightning trainer command line tool

optional arguments:
-h, --help            Show this help message and exit.
-c CONFIG, --config CONFIG
                        Path to a configuration file in json or yaml format.
--print_config [={comments,skip_null,skip_default}+]
                        Print configuration and exit.

subcommands:
For more details of each subcommand add it as argument followed by --help.

{fit,validate,test,predict,tune}
    fit                 Runs the full optimization routine.
    validate            Perform one evaluation epoch over the validation set.
    test                Perform one evaluation epoch over the test set.
    predict             Run inference on your data.
    tune                Runs routines to tune hyperparameters before training.
</code></pre></div></div> <h3 id="使用cli训练模型"> <a href="#使用cli训练模型" class="anchor-heading" aria-labelledby="使用cli训练模型"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 使用CLI训练模型 </h3> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python main.py fit
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">--help</code>参数查看可用选项:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ python main.py fit --help

usage: main.py [options] fit [-h] [-c CONFIG]
                            [--seed_everything SEED_EVERYTHING] [--trainer CONFIG]
                            ...
                            [--ckpt_path CKPT_PATH]
    --trainer.logger LOGGER

optional arguments:
&lt;class '__main__.DemoModel'&gt;:
    --model.out_dim OUT_DIM
                            (type: int, default: 10)
    --model.learning_rate LEARNING_RATE
                            (type: float, default: 0.02)
&lt;class 'lightning.pytorch.demos.boring_classes.BoringDataModule'&gt;:
--data CONFIG         Path to a configuration file.
--data.data_dir DATA_DIR
                        (type: str, default: ./)
</code></pre></div></div> <p>改变参数:</p> <div class="language-sh note highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># change the learning_rate</span>
python main.py fit <span class="nt">--model</span>.learning_rate 0.1

<span class="c"># change the output dimensions also</span>
python main.py fit <span class="nt">--model</span>.out_dim 10 <span class="nt">--model</span>.learning_rate 0.1

<span class="c"># change trainer and data arguments too</span>
python main.py fit <span class="nt">--model</span>.out_dim 2 <span class="nt">--model</span>.learning_rate 0.1 <span class="nt">--data</span>.data_dir <span class="s1">'~/'</span> <span class="nt">--trainer</span>.logger False
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">LightningModule</code> 和 <code class="language-plaintext highlighter-rouge">LightningDataModule</code>类中的<code class="language-plaintext highlighter-rouge">__init__</code>的参数在CLI中发挥作用，因此，想要一个参数可以配置，将其添加到类的<code class="language-plaintext highlighter-rouge">__init__</code>中。 最好在docstring中描述这些参数，这样可以通过<code class="language-plaintext highlighter-rouge">--help</code>进行查看，最好加上type hint.</p> <h2 id="cli中配置超参数-2"> <a href="#cli中配置超参数-2" class="anchor-heading" aria-labelledby="cli中配置超参数-2"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> CLI中配置超参数-2 </h2> <p>lightning支持混合使用模型和数据集，比如:</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Mix and match anything</span>
<span class="nv">$ </span>python main.py fit <span class="nt">--model</span><span class="o">=</span>GAN <span class="nt">--data</span><span class="o">=</span>MNIST
<span class="nv">$ </span>python main.py fit <span class="nt">--model</span><span class="o">=</span>Transformer <span class="nt">--data</span><span class="o">=</span>MNIST
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">LightningCLI</code>可以方便实现这一功能，不用像下面一样写过多代码:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># choose model
</span><span class="k">if</span> <span class="n">args</span><span class="p">.</span><span class="n">model</span> <span class="o">==</span> <span class="s">"gan"</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">GAN</span><span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">feat_dim</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">args</span><span class="p">.</span><span class="n">model</span> <span class="o">==</span> <span class="s">"transformer"</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Transformer</span><span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">feat_dim</span><span class="p">)</span>
<span class="p">...</span>

<span class="c1"># choose datamodule
</span><span class="k">if</span> <span class="n">args</span><span class="p">.</span><span class="n">data</span> <span class="o">==</span> <span class="s">"MNIST"</span><span class="p">:</span>
    <span class="n">datamodule</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">()</span>
<span class="k">elif</span> <span class="n">args</span><span class="p">.</span><span class="n">data</span> <span class="o">==</span> <span class="s">"imagenet"</span><span class="p">:</span>
    <span class="n">datamodule</span> <span class="o">=</span> <span class="n">Imagenet</span><span class="p">()</span>
<span class="p">...</span>

<span class="c1"># mix them!
</span><span class="n">trainer</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">datamodule</span><span class="p">)</span>
</code></pre></div></div> <h3 id="多个lightningmodules"> <a href="#多个lightningmodules" class="anchor-heading" aria-labelledby="多个lightningmodules"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 多个LightningModules </h3> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># main.py
</span><span class="kn">from</span> <span class="nn">lightning.pytorch.cli</span> <span class="kn">import</span> <span class="n">LightningCLI</span>
<span class="kn">from</span> <span class="nn">lightning.pytorch.demos.boring_classes</span> <span class="kn">import</span> <span class="n">DemoModel</span><span class="p">,</span> <span class="n">BoringDataModule</span>


<span class="k">class</span> <span class="nc">Model1</span><span class="p">(</span><span class="n">DemoModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"⚡"</span><span class="p">,</span> <span class="s">"using Model1"</span><span class="p">,</span> <span class="s">"⚡"</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">().</span><span class="n">configure_optimizers</span><span class="p">()</span>


<span class="k">class</span> <span class="nc">Model2</span><span class="p">(</span><span class="n">DemoModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"⚡"</span><span class="p">,</span> <span class="s">"using Model2"</span><span class="p">,</span> <span class="s">"⚡"</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">().</span><span class="n">configure_optimizers</span><span class="p">()</span>


<span class="n">cli</span> <span class="o">=</span> <span class="n">LightningCLI</span><span class="p">(</span><span class="n">datamodule_class</span><span class="o">=</span><span class="n">BoringDataModule</span><span class="p">)</span>
</code></pre></div></div> <p>现在可以在CLI中选择模型:</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># use Model1</span>
python main.py fit <span class="nt">--model</span> Model1

<span class="c"># use Model2</span>
python main.py fit <span class="nt">--model</span> Model2
</code></pre></div></div> <p class="note">如果不使用<code class="language-plaintext highlighter-rouge">model_class</code>参数，可以使用基类以及<code class="language-plaintext highlighter-rouge">subclass_mode_model=True</code>，这样cli只能接收给定基类的子类模型。</p> <h3 id="多个-lightningdatamodules"> <a href="#多个-lightningdatamodules" class="anchor-heading" aria-labelledby="多个-lightningdatamodules"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 多个 LightningDataModules </h3> <p>在<code class="language-plaintext highlighter-rouge">LightningCLI</code>中使用<code class="language-plaintext highlighter-rouge">datamodule_class</code>参数：</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># main.py
</span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">lightning.pytorch.cli</span> <span class="kn">import</span> <span class="n">LightningCLI</span>
<span class="kn">from</span> <span class="nn">lightning.pytorch.demos.boring_classes</span> <span class="kn">import</span> <span class="n">DemoModel</span><span class="p">,</span> <span class="n">BoringDataModule</span>


<span class="k">class</span> <span class="nc">FakeDataset1</span><span class="p">(</span><span class="n">BoringDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"⚡"</span><span class="p">,</span> <span class="s">"using FakeDataset1"</span><span class="p">,</span> <span class="s">"⚡"</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">random_train</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">FakeDataset2</span><span class="p">(</span><span class="n">BoringDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"⚡"</span><span class="p">,</span> <span class="s">"using FakeDataset2"</span><span class="p">,</span> <span class="s">"⚡"</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">random_train</span><span class="p">)</span>


<span class="n">cli</span> <span class="o">=</span> <span class="n">LightningCLI</span><span class="p">(</span><span class="n">DemoModel</span><span class="p">)</span>
</code></pre></div></div> <p>现在可以使用任意数据集:</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># use Model1</span>
python main.py fit <span class="nt">--data</span> FakeDataset1

<span class="c"># use Model2</span>
python main.py fit <span class="nt">--data</span> FakeDataset2
</code></pre></div></div> <p class="note">Instead of omitting the <code class="language-plaintext highlighter-rouge">datamodule_class</code> parameter, you can give a base class and <code class="language-plaintext highlighter-rouge">subclass_mode_data=True</code>. This will make the CLI only accept data modules that are a subclass of the given base class.</p> <h3 id="多个优化器"> <a href="#多个优化器" class="anchor-heading" aria-labelledby="多个优化器"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 多个优化器 </h3> <p>使用标准的优化器:</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python main.py fit <span class="nt">--optimizer</span> AdamW

python main.py fit <span class="nt">--optimizer</span> SGD <span class="nt">--optimizer</span>.lr<span class="o">=</span>0.01
</code></pre></div></div> <p>自定义优化器:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># main.py
</span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">lightning.pytorch.cli</span> <span class="kn">import</span> <span class="n">LightningCLI</span>
<span class="kn">from</span> <span class="nn">lightning.pytorch.demos.boring_classes</span> <span class="kn">import</span> <span class="n">DemoModel</span><span class="p">,</span> <span class="n">BoringDataModule</span>


<span class="k">class</span> <span class="nc">LitAdam</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">closure</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"⚡"</span><span class="p">,</span> <span class="s">"using LitAdam"</span><span class="p">,</span> <span class="s">"⚡"</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">FancyAdam</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">closure</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"⚡"</span><span class="p">,</span> <span class="s">"using FancyAdam"</span><span class="p">,</span> <span class="s">"⚡"</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="p">)</span>


<span class="n">cli</span> <span class="o">=</span> <span class="n">LightningCLI</span><span class="p">(</span><span class="n">DemoModel</span><span class="p">,</span> <span class="n">BoringDataModule</span><span class="p">)</span>
</code></pre></div></div> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># use LitAdam</span>
python main.py fit <span class="nt">--optimizer</span> LitAdam

<span class="c"># use FancyAdam</span>
python main.py fit <span class="nt">--optimizer</span> FancyAdam
</code></pre></div></div> <h3 id="多个scheduler"> <a href="#多个scheduler" class="anchor-heading" aria-labelledby="多个scheduler"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 多个scheduler </h3> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python main.py fit <span class="nt">--lr_scheduler</span> CosineAnnealingLR
python main.py fit <span class="nt">--lr_scheduler</span><span class="o">=</span>ReduceLROnPlateau <span class="nt">--lr_scheduler</span>.monitor<span class="o">=</span>epoch
</code></pre></div></div> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># main.py
</span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">lightning.pytorch.cli</span> <span class="kn">import</span> <span class="n">LightningCLI</span>
<span class="kn">from</span> <span class="nn">lightning.pytorch.demos.boring_classes</span> <span class="kn">import</span> <span class="n">DemoModel</span><span class="p">,</span> <span class="n">BoringDataModule</span>


<span class="k">class</span> <span class="nc">LitLRScheduler</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">lr_scheduler</span><span class="p">.</span><span class="n">CosineAnnealingLR</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"⚡"</span><span class="p">,</span> <span class="s">"using LitLRScheduler"</span><span class="p">,</span> <span class="s">"⚡"</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">step</span><span class="p">()</span>


<span class="n">cli</span> <span class="o">=</span> <span class="n">LightningCLI</span><span class="p">(</span><span class="n">DemoModel</span><span class="p">,</span> <span class="n">BoringDataModule</span><span class="p">)</span>
</code></pre></div></div> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># LitLRScheduler
</span><span class="n">python</span> <span class="n">main</span><span class="p">.</span><span class="n">py</span> <span class="n">fit</span> <span class="o">--</span><span class="n">lr_scheduler</span> <span class="n">LitLRScheduler</span>
</code></pre></div></div> <h3 id="其他包中的类"> <a href="#其他包中的类" class="anchor-heading" aria-labelledby="其他包中的类"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 其他包中的类 </h3> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">lightning.pytorch.cli</span> <span class="kn">import</span> <span class="n">LightningCLI</span>
<span class="kn">import</span> <span class="nn">my_code.models</span>  <span class="c1"># noqa: F401
</span><span class="kn">import</span> <span class="nn">my_code.data_modules</span>  <span class="c1"># noqa: F401
</span><span class="kn">import</span> <span class="nn">my_code.optimizers</span>  <span class="c1"># noqa: F401
</span>
<span class="n">cli</span> <span class="o">=</span> <span class="n">LightningCLI</span><span class="p">()</span>
</code></pre></div></div> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python main.py fit <span class="nt">--model</span> Model1 <span class="nt">--data</span> FakeDataset1 <span class="nt">--optimizer</span> LitAdam <span class="nt">--lr_scheduler</span> LitLRScheduler
</code></pre></div></div> <p class="note">The <code class="language-plaintext highlighter-rouge"># noqa: F401</code> comment avoids a linter warning that the import is unused.</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python main.py fit <span class="nt">--model</span> my_code.models.Model1
</code></pre></div></div> <h3 id="模型help"> <a href="#模型help" class="anchor-heading" aria-labelledby="模型help"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 模型help </h3> <p>用多个模型或数据集时CLI的help不会包含对应的参数，用该用以下的方式:</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python main.py fit <span class="nt">--model</span>.help Model1
python main.py fit <span class="nt">--data</span>.help FakeDataset2
python main.py fit <span class="nt">--optimizer</span>.help Adagrad
python main.py fit <span class="nt">--lr_scheduler</span>.help StepLR
</code></pre></div></div> <h2 id="cli中配置超参数-3"> <a href="#cli中配置超参数-3" class="anchor-heading" aria-labelledby="cli中配置超参数-3"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> CLI中配置超参数-3 </h2> <p>随着参数的增多从CLI中引入参数变得不现实，LightningCLI可以支持从配置文件中接收输入.</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python main.py fit <span class="nt">--config</span> config.yaml
</code></pre></div></div> <p>默认LightningCLI自动保存完整的YAML配置在log目录下。</p> <p>自动保存通过特定的回调<code class="language-plaintext highlighter-rouge">SaveConfigCallback</code>实现，这个回调时自动添加到Trainer上的，要禁用，实例化<code class="language-plaintext highlighter-rouge">LightningCLI</code>时传入<code class="language-plaintext highlighter-rouge">save_config_callback=None</code></p> <p>要改变名字使用:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cli</span> <span class="o">=</span> <span class="n">LightningCLI</span><span class="p">(...,</span> <span class="n">save_config_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s">"config_filename"</span><span class="p">:</span> <span class="s">"name.yaml"</span><span class="p">})</span>
</code></pre></div></div> <h3 id="为cli准备config文件"> <a href="#为cli准备config文件" class="anchor-heading" aria-labelledby="为cli准备config文件"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 为CLI准备config文件 </h3> <p>不运行命令只打印参数:</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python main.py fit <span class="nt">--print_config</span>
</code></pre></div></div> <p>会生成:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>seed_everything: null
trainer:
  logger: true
  ...
model:
  out_dim: 10
  learning_rate: 0.02
data:
  data_dir: ./
ckpt_path: null
</code></pre></div></div> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python main.py fit <span class="nt">--model</span> DemoModel <span class="nt">--print_config</span>
</code></pre></div></div> <p>生成:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>seed_everything: null
trainer:
  ...
model:
  class_path: lightning.pytorch.demos.boring_classes.DemoModel
  init_args:
    out_dim: 10
    learning_rate: 0.02
ckpt_path: null
</code></pre></div></div> <blockquote class="note"> <p>标准的实验过程是:</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Print a configuration to have as reference</span>
python main.py fit <span class="nt">--print_config</span> <span class="o">&gt;</span> config.yaml
<span class="c"># Modify the config to your liking - you can remove all default arguments</span>
nano config.yaml
<span class="c"># Fit your model using the edited configuration</span>
python main.py fit <span class="nt">--config</span> config.yaml
</code></pre></div> </div> </blockquote> <p>如果模型定义为:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># model.py
</span><span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">pl</span><span class="p">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">criterion</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">criterion</span>
</code></pre></div></div> <p>config将会是:</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">model</span><span class="pi">:</span>
  <span class="na">class_path</span><span class="pi">:</span> <span class="s">model.MyModel</span>
  <span class="na">init_args</span><span class="pi">:</span>
    <span class="na">criterion</span><span class="pi">:</span>
      <span class="na">class_path</span><span class="pi">:</span> <span class="s">torch.nn.CrossEntropyLoss</span>
      <span class="na">init_args</span><span class="pi">:</span>
        <span class="na">reduction</span><span class="pi">:</span> <span class="s">mean</span>
    <span class="s">...</span>
</code></pre></div></div> <p class="note">Lighting automatically registers all subclasses of <code class="language-plaintext highlighter-rouge">LightningModule</code>, so the complete import path is not required for them and can be replaced by the class name.</p> <h3 id="组合配置文件"> <a href="#组合配置文件" class="anchor-heading" aria-labelledby="组合配置文件"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 组合配置文件 </h3> <p>可以使用多个配置文件:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># config_1.yaml
trainer:
  num_epochs: 10
  ...

# config_2.yaml
trainer:
  num_epochs: 20
  ...
</code></pre></div></div> <p>会使用最后一个配置的值:</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>python main.py fit <span class="nt">--config</span> config_1.yaml <span class="nt">--config</span> config_2.yaml
</code></pre></div></div> <p>一组选项也可以放在多个文件中:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># trainer.yaml
num_epochs: 10

# model.yaml
out_dim: 7

# data.yaml
data_dir: ./data
</code></pre></div></div> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>python main.py fit <span class="nt">--trainer</span> trainer.yaml <span class="nt">--model</span> model.yaml <span class="nt">--data</span> data.yaml <span class="o">[</span>...]
</code></pre></div></div> <h2 id="cli中配置超参数-4"> <a href="#cli中配置超参数-4" class="anchor-heading" aria-labelledby="cli中配置超参数-4"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> CLI中配置超参数-4 </h2> <p>要自定义子命令的参数，在子命令前传递参数:</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>python main.py <span class="o">[</span>before] <span class="o">[</span>subcommand] <span class="o">[</span>after]
<span class="nv">$ </span>python main.py  ...         fit       ...
</code></pre></div></div> <p>比如:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># config.yaml
fit:
    trainer:
        max_steps: 100
test:
    trainer:
        max_epochs: 10
</code></pre></div></div> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># full routine with max_steps = 100</span>
<span class="nv">$ </span>python main.py <span class="nt">--config</span> config.yaml fit

<span class="c"># test only with max_epochs = 10</span>
<span class="nv">$ </span>python main.py <span class="nt">--config</span> config.yaml <span class="nb">test</span>
</code></pre></div></div> <p>通过环境变量使用config:</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>python main.py fit <span class="nt">--trainer</span> <span class="s2">"</span><span class="nv">$TRAINER_CONFIG</span><span class="s2">"</span> <span class="nt">--model</span> <span class="s2">"</span><span class="nv">$MODEL_CONFIG</span><span class="s2">"</span> <span class="o">[</span>...]
</code></pre></div></div> <p>直接从环境变量运行:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cli</span> <span class="o">=</span> <span class="n">LightningCLI</span><span class="p">(...,</span> <span class="n">parser_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s">"default_env"</span><span class="p">:</span> <span class="bp">True</span><span class="p">})</span>
</code></pre></div></div> <p>运行：</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>python main.py fit <span class="nt">--help</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>usage: main.py [options] fit [-h] [-c CONFIG]
                            ...

optional arguments:
...
ARG:   --model.out_dim OUT_DIM
ENV:   PL_FIT__MODEL__OUT_DIM
                        (type: int, default: 10)
ARG:   --model.learning_rate LEARNING_RATE
ENV:   PL_FIT__MODEL__LEARNING_RATE
                        (type: float, default: 0.02)
</code></pre></div></div> <p>现在通过环境变量定义:</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># set the options via env vars</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">PL_FIT__MODEL__LEARNING_RATE</span><span class="o">=</span>0.01
<span class="nv">$ </span><span class="nb">export </span><span class="nv">PL_FIT__MODEL__OUT_DIM</span><span class="o">=</span>5

<span class="nv">$ </span>python main.py fit
</code></pre></div></div> <p>设置默认的config文件:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cli</span> <span class="o">=</span> <span class="n">LightningCLI</span><span class="p">(</span><span class="n">MyModel</span><span class="p">,</span> <span class="n">MyDataModule</span><span class="p">,</span> <span class="n">parser_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s">"default_config_files"</span><span class="p">:</span> <span class="p">[</span><span class="s">"my_cli_defaults.yaml"</span><span class="p">]})</span>
</code></pre></div></div> <p>或者:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cli</span> <span class="o">=</span> <span class="n">LightningCLI</span><span class="p">(</span><span class="n">MyModel</span><span class="p">,</span> <span class="n">MyDataModule</span><span class="p">,</span> <span class="n">parser_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s">"fit"</span><span class="p">:</span> <span class="p">{</span><span class="s">"default_config_files"</span><span class="p">:</span> <span class="p">[</span><span class="s">"my_fit_defaults.yaml"</span><span class="p">]}})</span>
</code></pre></div></div> <h3 id="变量插入"> <a href="#变量插入" class="anchor-heading" aria-labelledby="变量插入"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 变量插入 </h3> <p>首先安装</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>omegaconf
</code></pre></div></div> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">model</span><span class="pi">:</span>
  <span class="na">encoder_layers</span><span class="pi">:</span> <span class="m">12</span>
  <span class="na">decoder_layers</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">${model.encoder_layers}</span>
  <span class="pi">-</span> <span class="m">4</span>
</code></pre></div></div> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cli</span> <span class="o">=</span> <span class="n">LightningCLI</span><span class="p">(</span><span class="n">MyModel</span><span class="p">,</span> <span class="n">parser_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s">"parser_mode"</span><span class="p">:</span> <span class="s">"omegaconf"</span><span class="p">})</span>
</code></pre></div></div> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python main.py <span class="nt">--model</span>.encoder_layers<span class="o">=</span>12
</code></pre></div></div> <p class="note">变量插入有时并不是正确的方法。当一个参数必须从其他设置得到时，不应该由CLI用户在配置文件中设置，比如data和model需要batch_size相同，那么应该使用参数连接而不是变量插入。</p> <h2 id="cli中配置超参数-5"> <a href="#cli中配置超参数-5" class="anchor-heading" aria-labelledby="cli中配置超参数-5"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> CLI中配置超参数-5 </h2> <p>CLI的目的是尽量减少代码更改，类一旦实例化,CLI会自动调用与子命令关联的trainer函数，可以使用以下代码:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cli</span> <span class="o">=</span> <span class="n">LightningCLI</span><span class="p">(</span><span class="n">MyModel</span><span class="p">,</span> <span class="n">run</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>  <span class="c1"># True by default
# you'll have to call fit yourself:
</span><span class="n">cli</span><span class="p">.</span><span class="n">trainer</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cli</span><span class="p">.</span><span class="n">model</span><span class="p">)</span>
</code></pre></div></div> <p>不将子命令添加到parser.在实现自定义的逻辑而不去继承CLI时比较有用，但同时又保留了CLI的实例化和参数传递功能。</p> <h3 id="trainer回调和class-type参数"> <a href="#trainer回调和class-type参数" class="anchor-heading" aria-labelledby="trainer回调和class-type参数"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Trainer回调和class type参数 </h3> <p>Trainer类的一个很重要的参数是callbacks.不像其他的参数一样，callback应该是Callback子类的示例list.要在配置文件中给出参数，每个callback必须以字典给出,包括class_path entry(给出类的import路径)和init_args(实例化参数),一个简单的定义了两个callback的配置文件如下:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>trainer:
  callbacks:
    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        patience: 5
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        ...
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">Trainer</code>中的任意参数以及用户扩展的<code class="language-plaintext highlighter-rouge">LightningModule</code>和<code class="language-plaintext highlighter-rouge">LightningDataModule</code>都可以用相同的方式进行配置。如果定义了子类的包在LightningCLI类之前运行，就可以不适用完整的import路径而是直接使用名字。</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>python ... <span class="se">\</span>
    <span class="nt">--trainer</span>.callbacks+<span class="o">={</span>CALLBACK_1_NAME<span class="o">}</span> <span class="se">\</span>
    <span class="nt">--trainer</span>.callbacks.<span class="o">{</span>CALLBACK_1_ARGS_1<span class="o">}=</span>... <span class="se">\</span>
    <span class="nt">--trainer</span>.callbacks.<span class="o">{</span>CALLBACK_1_ARGS_2<span class="o">}=</span>... <span class="se">\</span>
    ...
    <span class="nt">--trainer</span>.callbacks+<span class="o">={</span>CALLBACK_N_NAME<span class="o">}</span> <span class="se">\</span>
    <span class="nt">--trainer</span>.callbacks.<span class="o">{</span>CALLBACK_N_ARGS_1<span class="o">}=</span>... <span class="se">\</span>
    ...
</code></pre></div></div> <p class="note">Serialized config files (e.g. <code class="language-plaintext highlighter-rouge">--print_config</code> or <code class="language-plaintext highlighter-rouge">SaveConfigCallback</code>) always have the full class_path, even when class name shorthand notation is used in the command line or in input config files.</p> <h3 id="多个模型和数据集"> <a href="#多个模型和数据集" class="anchor-heading" aria-labelledby="多个模型和数据集"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 多个模型和数据集 </h3> <p>A CLI can be written such that a model and/or a datamodule is specified by an import path and init arguments. For example, with a tool implemented as:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cli</span> <span class="o">=</span> <span class="n">LightningCLI</span><span class="p">(</span><span class="n">MyModelBaseClass</span><span class="p">,</span> <span class="n">MyDataModuleBaseClass</span><span class="p">,</span> <span class="n">subclass_mode_model</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">subclass_mode_data</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>model:
  class_path: mycode.mymodels.MyModel
  init_args:
    decoder_layers:
    - 2
    - 4
    encoder_layers: 12
data:
  class_path: mycode.mydatamodules.MyDataModule
  init_args:
    ...
trainer:
  callbacks:
    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        patience: 5
    ...
</code></pre></div></div> <p>Only model classes that are a subclass of <code class="language-plaintext highlighter-rouge">MyModelBaseClass</code> would be allowed, and similarly, only subclasses of <code class="language-plaintext highlighter-rouge">MyDataModuleBaseClass</code>. If as base classes <code class="language-plaintext highlighter-rouge">LightningModule</code> and <code class="language-plaintext highlighter-rouge">LightningDataModule</code> is given, then the CLI would allow any lightning module and data module.</p> <p>子类模式下<code class="language-plaintext highlighter-rouge">--help</code>选项不会显示特定子类的信息:</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>python trainer.py fit <span class="nt">--model</span>.help mycode.mymodels.MyModel
<span class="nv">$ </span>python trainer.py fit <span class="nt">--model</span> mycode.mymodels.MyModel <span class="nt">--print_config</span>
</code></pre></div></div> <h3 id="有多个子模块的模型"> <a href="#有多个子模块的模型" class="anchor-heading" aria-labelledby="有多个子模块的模型"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 有多个子模块的模型 </h3> <p>我们经常需要几个模块，每个模块有自己的配置，一个方式是创建一个模块有每个子模块的参数作为初始参数，这又叫做依赖注入，可以很好的解耦代码。</p> <p>由于模型的初始参数作为类的type hint,在配置文件中通过class_path和init_args给出，比如模型可以实现为:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MyMainModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">decoder</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="s">"""Example encoder-decoder submodules model

        Args:
            encoder: Instance of a module for encoding
            decoder: Instance of a module for decoding
        """</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>
</code></pre></div></div> <p>如果CLI实现为<code class="language-plaintext highlighter-rouge">LightningCLI(MyMainModel)</code>，配置文件如下:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>model:
  encoder:
    class_path: mycode.myencoders.MyEncoder
    init_args:
      ...
  decoder:
    class_path: mycode.mydecoders.MyDecoder
    init_args:
      ...
</code></pre></div></div> <p>也可以结合<code class="language-plaintext highlighter-rouge">subclass_mode_model=True</code>和子模块，这会有两层class_path.</p> <h3 id="固定optimizer和scheduler"> <a href="#固定optimizer和scheduler" class="anchor-heading" aria-labelledby="固定optimizer和scheduler"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 固定optimizer和scheduler </h3> <p>有的时候需要固定优化器和scheduler,可以手动的为CLI的子类添加参数，</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MyLightningCLI</span><span class="p">(</span><span class="n">LightningCLI</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">add_arguments_to_parser</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parser</span><span class="p">):</span>
        <span class="n">parser</span><span class="p">.</span><span class="n">add_optimizer_args</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">)</span>
        <span class="n">parser</span><span class="p">.</span><span class="n">add_lr_scheduler_args</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">lr_scheduler</span><span class="p">.</span><span class="n">ExponentialLR</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>optimizer:
  lr: 0.01
lr_scheduler:
  gamma: 0.2
model:
  ...
trainer:
  ...
</code></pre></div></div> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>python trainer.py fit <span class="nt">--optimizer</span>.lr<span class="o">=</span>0.01 <span class="nt">--lr_scheduler</span>.gamma<span class="o">=</span>0.2
</code></pre></div></div> <h3 id="多个optimizer和scheduler"> <a href="#多个optimizer和scheduler" class="anchor-heading" aria-labelledby="多个optimizer和scheduler"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 多个optimizer和scheduler </h3> <p>By default, the CLIs support multiple optimizers and/or learning schedulers, automatically implementing <code class="language-plaintext highlighter-rouge">configure_optimizers</code>. This behavior can be disabled by providing <code class="language-plaintext highlighter-rouge">auto_configure_optimizers=False</code> on instantiation of <code class="language-plaintext highlighter-rouge">LightningCLI</code>. This would be required for example to support multiple optimizers, for each selecting a particular optimizer class. Similar to multiple submodules, this can be done via dependency injection. Unlike the submodules, it is not possible to expect an instance of a class, because optimizers require the module’s parameters to optimize, which are only available after instantiation of the module. Learning schedulers are a similar situation, requiring an optimizer instance. For these cases, dependency injection involves providing a function that instantiates the respective class when called.</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Iterable</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Optimizer</span>


<span class="n">OptimizerCallable</span> <span class="o">=</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Iterable</span><span class="p">],</span> <span class="n">Optimizer</span><span class="p">]</span>


<span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer1</span><span class="p">:</span> <span class="n">OptimizerCallable</span><span class="p">,</span> <span class="n">optimizer2</span><span class="p">:</span> <span class="n">OptimizerCallable</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">optimizer1</span> <span class="o">=</span> <span class="n">optimizer1</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">optimizer2</span> <span class="o">=</span> <span class="n">optimizer2</span>

    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">optimizer1</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">optimizer1</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">parameters</span><span class="p">())</span>
        <span class="n">optimizer2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">optimizer2</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">parameters</span><span class="p">())</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">optimizer1</span><span class="p">,</span> <span class="n">optimizer2</span><span class="p">]</span>


<span class="n">cli</span> <span class="o">=</span> <span class="n">MyLightningCLI</span><span class="p">(</span><span class="n">MyModel</span><span class="p">,</span> <span class="n">auto_configure_optimizers</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div> <p>Note the type <code class="language-plaintext highlighter-rouge">Callable[[Iterable], Optimizer]</code>, which denotes a function that receives a singe argument, some learnable parameters, and returns an optimizer instance. With this, from the command line it is possible to select the class and init arguments for each of the optimizers, as follows:</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>python trainer.py fit <span class="se">\</span>
    <span class="nt">--model</span>.optimizer1<span class="o">=</span>Adam <span class="se">\</span>
    <span class="nt">--model</span>.optimizer1.lr<span class="o">=</span>0.01 <span class="se">\</span>
    <span class="nt">--model</span>.optimizer2<span class="o">=</span>AdamW <span class="se">\</span>
    <span class="nt">--model</span>.optimizer2.lr<span class="o">=</span>0.0001
</code></pre></div></div> <p>In the example above, the <code class="language-plaintext highlighter-rouge">OptimizerCallable</code> type alias was created to illustrate what the type hint means. For convenience, this type alias and one for learning schedulers is available in the cli module. An example of a model that uses dependency injection for an optimizer and a learning scheduler is:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">lightning.pytorch.cli</span> <span class="kn">import</span> <span class="n">OptimizerCallable</span><span class="p">,</span> <span class="n">LRSchedulerCallable</span><span class="p">,</span> <span class="n">LightningCLI</span>


<span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="p">:</span> <span class="n">OptimizerCallable</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">,</span>
        <span class="n">scheduler</span><span class="p">:</span> <span class="n">LRSchedulerCallable</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">lr_scheduler</span><span class="p">.</span><span class="n">ConstantLR</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">scheduler</span>

    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">parameters</span><span class="p">())</span>
        <span class="n">scheduler</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">scheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="s">"optimizer"</span><span class="p">:</span> <span class="n">optimizer</span><span class="p">,</span> <span class="s">"lr_scheduler"</span><span class="p">:</span> <span class="n">scheduler</span><span class="p">}</span>


<span class="n">cli</span> <span class="o">=</span> <span class="n">MyLightningCLI</span><span class="p">(</span><span class="n">MyModel</span><span class="p">,</span> <span class="n">auto_configure_optimizers</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div> <p>Note that for this example, classes are used as defaults. This is compatible with the type hints, since they are also callables that receive the same first argument and return an instance of the class. Classes that have more than one required argument will not work as default. For these cases a lambda function can be used, e.g. <code class="language-plaintext highlighter-rouge">optimizer: OptimizerCallable = lambda p: torch.optim.SGD(p, lr=0.01)</code>.</p> <h3 id="从python运行"> <a href="#从python运行" class="anchor-heading" aria-labelledby="从python运行"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 从python运行 </h3> <p><code class="language-plaintext highlighter-rouge">LightningCLI</code>尽管是拿来辅助命令行操作，某些情况下可以直接从python中运行。首先实现一个正常的CLI脚本，但是添加一个args=None.</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">lightning.pytorch.cli</span> <span class="kn">import</span> <span class="n">ArgsType</span><span class="p">,</span> <span class="n">LightningCLI</span>


<span class="k">def</span> <span class="nf">cli_main</span><span class="p">(</span><span class="n">args</span><span class="p">:</span> <span class="n">ArgsType</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
    <span class="n">cli</span> <span class="o">=</span> <span class="n">LightningCLI</span><span class="p">(</span><span class="n">MyModel</span><span class="p">,</span> <span class="p">...,</span> <span class="n">args</span><span class="o">=</span><span class="n">args</span><span class="p">)</span>
    <span class="p">...</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">cli_main</span><span class="p">()</span>
</code></pre></div></div> <p>然后就可以import <code class="language-plaintext highlighter-rouge">cli_main</code>函数运行，执行<code class="language-plaintext highlighter-rouge">my_cli.py --trainer.max_epochs=100 --model.encoder_layers=24</code>，等价于:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">my_module.my_cli</span> <span class="kn">import</span> <span class="n">cli_main</span>

<span class="n">cli_main</span><span class="p">([</span><span class="s">"--trainer.max_epochs=100"</span><span class="p">,</span> <span class="s">"--model.encoder_layers=24"</span><span class="p">])</span>
</code></pre></div></div> <p>命令行的所有特征都可以使用，可以给args一个string list或者dict或者jsonargparse,比如在jupyter中:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">args</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"trainer"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s">"max_epochs"</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s">"model"</span><span class="p">:</span> <span class="p">{},</span>
<span class="p">}</span>

<span class="n">args</span><span class="p">[</span><span class="s">"model"</span><span class="p">][</span><span class="s">"encoder_layers"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">cli_main</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
<span class="n">args</span><span class="p">[</span><span class="s">"model"</span><span class="p">][</span><span class="s">"encoder_layers"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">cli_main</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
<span class="n">args</span><span class="p">[</span><span class="s">"trainer"</span><span class="p">][</span><span class="s">"max_epochs"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">cli_main</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
</code></pre></div></div> <p class="note"><code class="language-plaintext highlighter-rouge">args</code>参数在从命令行运行的时候必须是<code class="language-plaintext highlighter-rouge">None</code>,这样才会使用<code class="language-plaintext highlighter-rouge">sys.argv</code>作为参数，注意， <code class="language-plaintext highlighter-rouge">trainer_defaults</code>的目的和<code class="language-plaintext highlighter-rouge">args</code>不同。可以在<code class="language-plaintext highlighter-rouge">cli_main</code>函数中使用<code class="language-plaintext highlighter-rouge">trainer_default</code>来更改一些trainer参数的默认值。</p> <h2 id="cli中配置超参数-6"> <a href="#cli中配置超参数-6" class="anchor-heading" aria-labelledby="cli中配置超参数-6"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> CLI中配置超参数-6 </h2> <p>自定义 <code class="language-plaintext highlighter-rouge">LightningCLI</code>.</p> <p>LightningCLI的初始化参数可以用来自定义一些东西，比如工具描述，环境变量解析，实例化trainer以及配置解析等。但是初始化参数大多数情况下不够用。这个类提供了一些自定义能力，LightningCLI用到的参数解析类是<code class="language-plaintext highlighter-rouge">LightningArgumentParser</code>，这是argparse的扩展，添加了额外的方法来添加参数，比如<code class="language-plaintext highlighter-rouge">add_class_arguments()</code>从类的init中添加参数。</p> <p><code class="language-plaintext highlighter-rouge">LightningCLI</code>的<code class="language-plaintext highlighter-rouge">add_arguments_to_parser()</code>方法可以用来实现添加更多的参数，解析之后参数保存在类的<code class="language-plaintext highlighter-rouge">config</code>属性之下，<code class="language-plaintext highlighter-rouge">LightningCLI</code>类还有两个在trainer之前和之后运行的方法，<code class="language-plaintext highlighter-rouge">before_&lt;subcommand&gt;</code> 和 <code class="language-plaintext highlighter-rouge">after_&lt;subcommand&gt;</code>.比如在fit前后发送邮件:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MyLightningCLI</span><span class="p">(</span><span class="n">LightningCLI</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">add_arguments_to_parser</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parser</span><span class="p">):</span>
        <span class="n">parser</span><span class="p">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">"--notification_email"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s">"will@email.com"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">before_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">send_email</span><span class="p">(</span><span class="n">address</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">[</span><span class="s">"notification_email"</span><span class="p">],</span> <span class="n">message</span><span class="o">=</span><span class="s">"trainer.fit starting"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">after_fit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">send_email</span><span class="p">(</span><span class="n">address</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">[</span><span class="s">"notification_email"</span><span class="p">],</span> <span class="n">message</span><span class="o">=</span><span class="s">"trainer.fit finished"</span><span class="p">)</span>


<span class="n">cli</span> <span class="o">=</span> <span class="n">MyLightningCLI</span><span class="p">(</span><span class="n">MyModel</span><span class="p">)</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">self.config</code>对象是一个命名空间，keys是全局选项。比如，实例化trainer类的参数可以在<code class="language-plaintext highlighter-rouge">self.config['fit']['trainer']</code>中找到.</p> <h3 id="强制callback"> <a href="#强制callback" class="anchor-heading" aria-labelledby="强制callback"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 强制callback </h3> <p>可以通过在命令行传递或者在config中通过<code class="language-plaintext highlighter-rouge">class_path</code>和<code class="language-plaintext highlighter-rouge">init_args</code>来添加callback.但是特定的callback必须和模型耦合在一起，可以想下面这样实现:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">lightning.pytorch.callbacks</span> <span class="kn">import</span> <span class="n">EarlyStopping</span>


<span class="k">class</span> <span class="nc">MyLightningCLI</span><span class="p">(</span><span class="n">LightningCLI</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">add_arguments_to_parser</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parser</span><span class="p">):</span>
        <span class="n">parser</span><span class="p">.</span><span class="n">add_lightning_class_args</span><span class="p">(</span><span class="n">EarlyStopping</span><span class="p">,</span> <span class="s">"my_early_stopping"</span><span class="p">)</span>
        <span class="n">parser</span><span class="p">.</span><span class="n">set_defaults</span><span class="p">({</span><span class="s">"my_early_stopping.monitor"</span><span class="p">:</span> <span class="s">"val_loss"</span><span class="p">,</span> <span class="s">"my_early_stopping.patience"</span><span class="p">:</span> <span class="mi">5</span><span class="p">})</span>


<span class="n">cli</span> <span class="o">=</span> <span class="n">MyLightningCLI</span><span class="p">(</span><span class="n">MyModel</span><span class="p">)</span>
</code></pre></div></div> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">model</span><span class="pi">:</span>
  <span class="s">...</span>
<span class="na">trainer</span><span class="pi">:</span>
  <span class="s">...</span>
<span class="na">my_early_stopping</span><span class="pi">:</span>
  <span class="na">patience</span><span class="pi">:</span> <span class="m">5</span>
</code></pre></div></div> <h3 id="class-type-defaults"> <a href="#class-type-defaults" class="anchor-heading" aria-labelledby="class-type-defaults"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Class type defaults </h3> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MyMainModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">backbone</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">(</span><span class="n">encoder_layers</span><span class="o">=</span><span class="mi">24</span><span class="p">),</span>  <span class="c1"># BAD PRACTICE!
</span>    <span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">backbone</span> <span class="o">=</span> <span class="n">backbone</span>
</code></pre></div></div> <p>正常的类是可以修改的，如上面的例子。<code class="language-plaintext highlighter-rouge">MyModel</code>的实例在定义了<code class="language-plaintext highlighter-rouge">MyMainModel</code>的模块第一次import时创建，这意味着backbone的默认值会在CLI类运行<code class="language-plaintext highlighter-rouge">seed_everything</code>之前初始化。 如果多次用到了MyMainModel，backbone不会被覆盖，而是在多个地方使用这个实例，使用实例作为默认值也无法生成完整的配置文件。</p> <p>比较好的解决方法是不去设置默认值或者特定值，在init中检查并实例化。如果类参数没有默认值并使用了CLI子类，可以使用下面的方式:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">default_backbone</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"class_path"</span><span class="p">:</span> <span class="s">"import.path.of.MyModel"</span><span class="p">,</span>
    <span class="s">"init_args"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s">"encoder_layers"</span><span class="p">:</span> <span class="mi">24</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">}</span>


<span class="k">class</span> <span class="nc">MyLightningCLI</span><span class="p">(</span><span class="n">LightningCLI</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">add_arguments_to_parser</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parser</span><span class="p">):</span>
        <span class="n">parser</span><span class="p">.</span><span class="n">set_defaults</span><span class="p">({</span><span class="s">"model.backbone"</span><span class="p">:</span> <span class="n">default_backbone</span><span class="p">})</span>
</code></pre></div></div> <p>或者:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">jsonargparse</span> <span class="kn">import</span> <span class="n">lazy_instance</span>


<span class="k">class</span> <span class="nc">MyLightningCLI</span><span class="p">(</span><span class="n">LightningCLI</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">add_arguments_to_parser</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parser</span><span class="p">):</span>
        <span class="n">parser</span><span class="p">.</span><span class="n">set_defaults</span><span class="p">({</span><span class="s">"model.backbone"</span><span class="p">:</span> <span class="n">lazy_instance</span><span class="p">(</span><span class="n">MyModel</span><span class="p">,</span> <span class="n">encoder_layers</span><span class="o">=</span><span class="mi">24</span><span class="p">)})</span>
</code></pre></div></div> <h3 id="参数链接"> <a href="#参数链接" class="anchor-heading" aria-labelledby="参数链接"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 参数链接 </h3> <p>另一种扩展CLI的方式是模型和数据模块具有一个共同的参数，比如两个类都需要知道batchsize,在配置文件中写两次十分容易出错，可以只写一次然后进行广播。</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MyLightningCLI</span><span class="p">(</span><span class="n">LightningCLI</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">add_arguments_to_parser</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parser</span><span class="p">):</span>
        <span class="n">parser</span><span class="p">.</span><span class="n">link_arguments</span><span class="p">(</span><span class="s">"data.batch_size"</span><span class="p">,</span> <span class="s">"model.batch_size"</span><span class="p">)</span>


<span class="n">cli</span> <span class="o">=</span> <span class="n">MyLightningCLI</span><span class="p">(</span><span class="n">MyModel</span><span class="p">,</span> <span class="n">MyDataModule</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ python trainer.py fit --help
  ...
    --data.batch_size BATCH_SIZE
                          Number of samples in a batch (type: int, default: 8)

  Linked arguments:
    data.batch_size --&gt; model.batch_size
                          Number of samples in a batch (type: int)
</code></pre></div></div> <p>有时一个参数值只有在类实例化之后才能使用，一个例子是模型需要类的数量来实例化连接层，但是在实例化数据模块的时候才能得到类数，可以如下面这样:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MyLightningCLI</span><span class="p">(</span><span class="n">LightningCLI</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">add_arguments_to_parser</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parser</span><span class="p">):</span>
        <span class="n">parser</span><span class="p">.</span><span class="n">link_arguments</span><span class="p">(</span><span class="s">"data.num_classes"</span><span class="p">,</span> <span class="s">"model.num_classes"</span><span class="p">,</span> <span class="n">apply_on</span><span class="o">=</span><span class="s">"instantiate"</span><span class="p">)</span>


<span class="n">cli</span> <span class="o">=</span> <span class="n">MyLightningCLI</span><span class="p">(</span><span class="n">MyClassModel</span><span class="p">,</span> <span class="n">MyDataModule</span><span class="p">)</span>
</code></pre></div></div> <p class="note">The linking of arguments is intended for things that are meant to be non-configurable. This improves the CLI user experience since it avoids the need to provide more parameters. A related concept is a variable interpolation that keeps things configurable.</p> <h1 id="checkpoint"> <a href="#checkpoint" class="anchor-heading" aria-labelledby="checkpoint"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> checkpoint </h1> <h1 id="实验管理"> <a href="#实验管理" class="anchor-heading" aria-labelledby="实验管理"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 实验管理 </h1> <h1 id="progress-bar"> <a href="#progress-bar" class="anchor-heading" aria-labelledby="progress-bar"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> PROGRESS BAR </h1> <p>Lightning支持两种进度条tqdm和rich,默认使用tqdm</p> <p>也可以使用 <code class="language-plaintext highlighter-rouge">ProgressBar</code>类自己实现进度条。</p> <h2 id="richprogressbar"> <a href="#richprogressbar" class="anchor-heading" aria-labelledby="richprogressbar"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> RichProgressBar </h2> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">lightning.pytorch.callbacks</span> <span class="kn">import</span> <span class="n">RichProgressBar</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">RichProgressBar</span><span class="p">()])</span>
</code></pre></div></div> <p>自定义<code class="language-plaintext highlighter-rouge">RichProgressBar</code>:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">lightning.pytorch.callbacks</span> <span class="kn">import</span> <span class="n">RichProgressBar</span>
<span class="kn">from</span> <span class="nn">lightning.pytorch.callbacks.progress.rich_progress</span> <span class="kn">import</span> <span class="n">RichProgressBarTheme</span>

<span class="c1"># create your own theme!
</span><span class="n">progress_bar</span> <span class="o">=</span> <span class="n">RichProgressBar</span><span class="p">(</span>
    <span class="n">theme</span><span class="o">=</span><span class="n">RichProgressBarTheme</span><span class="p">(</span>
        <span class="n">description</span><span class="o">=</span><span class="s">"green_yellow"</span><span class="p">,</span>
        <span class="n">progress_bar</span><span class="o">=</span><span class="s">"green1"</span><span class="p">,</span>
        <span class="n">progress_bar_finished</span><span class="o">=</span><span class="s">"green1"</span><span class="p">,</span>
        <span class="n">progress_bar_pulse</span><span class="o">=</span><span class="s">"#6206E0"</span><span class="p">,</span>
        <span class="n">batch_progress</span><span class="o">=</span><span class="s">"green_yellow"</span><span class="p">,</span>
        <span class="n">time</span><span class="o">=</span><span class="s">"grey82"</span><span class="p">,</span>
        <span class="n">processing_speed</span><span class="o">=</span><span class="s">"grey82"</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="s">"grey82"</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">callbacks</span><span class="o">=</span><span class="n">progress_bar</span><span class="p">)</span>
</code></pre></div></div> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">rich.progress</span> <span class="kn">import</span> <span class="n">TextColumn</span>

<span class="n">custom_column</span> <span class="o">=</span> <span class="n">TextColumn</span><span class="p">(</span><span class="s">"[progress.description]Custom Rich Progress Bar!"</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">CustomRichProgressBar</span><span class="p">(</span><span class="n">RichProgressBar</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">configure_columns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">custom_column</span><span class="p">]</span>


<span class="n">progress_bar</span> <span class="o">=</span> <span class="n">CustomRichProgressBar</span><span class="p">()</span>
</code></pre></div></div> <p>如果想要每个epoch后现实一个新的进度条应该开启<code class="language-plaintext highlighter-rouge">RichProgressBar.leave</code>，</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">lightning.pytorch.callbacks</span> <span class="kn">import</span> <span class="n">RichProgressBar</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">RichProgressBar</span><span class="p">(</span><span class="n">leave</span><span class="o">=</span><span class="bp">True</span><span class="p">)])</span>
</code></pre></div></div> <p class="note">要禁用进度条，使用<code class="language-plaintext highlighter-rouge">trainer = Trainer(enable_progress_bar=False)</code></p> <h1 id="gpu"> <a href="#gpu" class="anchor-heading" aria-labelledby="gpu"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> GPU </h1> <h1 id="并行"> <a href="#并行" class="anchor-heading" aria-labelledby="并行"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 并行 </h1> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
